from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, or_
from sqlalchemy.orm import selectinload
from typing import List, Optional, Dict, Any
from datetime import datetime
import pandas as pd
import io
import re
import aiohttp
import asyncio
from difflib import SequenceMatcher
import json
import time
import uuid
from pathlib import Path
import pymorphy2
from functools import lru_cache
from pydantic import BaseModel

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
morph = pymorphy2.MorphAnalyzer()

def normalize_russian_text(text: str) -> str:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ (–∏–º–µ–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂, –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ).
    –¢–∞–∫–∂–µ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–∞ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã.
    """
    if not text:
        return ""
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Å–ª–∞ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    numbers_and_special = re.findall(r'\d+|[^\w\s]', text)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞
    words = re.findall(r'\b[–∞-—è–ê-–Ø]+\b', text)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ
    normalized_words = []
    for word in words:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ä–∞–∑–±–æ—Ä—ã —Å–ª–æ–≤–∞
        parsed = morph.parse(word)
        if parsed:
            # –ë–µ—Ä–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ä–∞–∑–±–æ—Ä
            normal_form = parsed[0].normal_form
            normalized_words.append(normal_form)
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –æ–±—Ä–∞—Ç–Ω–æ, –≤–∫–ª—é—á–∞—è —á–∏—Å–ª–∞ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    result = ' '.join(normalized_words + numbers_and_special)
    return result.strip()

@lru_cache(maxsize=1000)
def get_normalized_text(text: str) -> str:
    """
    –ö—ç—à–∏—Ä—É—é—â–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è normalize_russian_text
    """
    return normalize_russian_text(text)

from database import get_db
from models import User, ApiKey, AiProcessingLog, MatchingNomenclature
from ..dependencies import get_current_user
from ..schemas import AIMatchingResponse, MatchingResult
from ..utils.api_key import get_api_key

# –ú–æ–¥–µ–ª–∏ –¥–ª—è Excel —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞
class ExcelRow(BaseModel):
    id: str
    –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: str
    –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π_–∞—Ä—Ç–∏–∫—É–ª: str
    –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: float
    –µ–¥–∏–Ω–∏—Ü–∞_–∏–∑–º–µ—Ä–µ–Ω–∏—è: str
    –Ω–∞—à_–∞—Ä—Ç–∏–∫—É–ª: Optional[str] = None
    –∞—Ä—Ç–∏–∫—É–ª_bl: Optional[str] = None
    –Ω–æ–º–µ—Ä_1—Å: Optional[str] = None
    —Å—Ç–æ–∏–º–æ—Å—Ç—å: Optional[float] = None
    —Å—Ç–∞—Ç—É—Å_—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: Optional[str] = "pending"
    —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: Optional[int] = 0
    –≤–∞—Ä–∏–∞–Ω—Ç—ã_–ø–æ–¥–±–æ—Ä–∞: Optional[List[dict]] = []
    –≤—ã–±—Ä–∞–Ω–Ω—ã–π_–≤–∞—Ä–∏–∞–Ω—Ç: Optional[int] = None  # –ò–Ω–¥–µ–∫—Å –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞

class ExcelDataRequest(BaseModel):
    data: List[ExcelRow]

class ExcelParseResponse(BaseModel):
    success: bool
    data: List[ExcelRow]
    message: Optional[str] = None

class ExcelMatchResponse(BaseModel):
    success: bool
    matched_data: List[ExcelRow]
    statistics: Dict[str, Any]
    message: Optional[str] = None

async def process_natural_language_query(query: str, db: AsyncSession) -> dict:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
    """
    print(f"ü§ñ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
    try:
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
        normalized_query = get_normalized_text(query)
        print(f"üîç –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: '{normalized_query}' (–±—ã–ª–æ: '{query}')")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        query_type = "unknown"
        if any(word in normalized_query.lower() for word in ["–Ω–∞–π—Ç–∏", "–ø–æ–∏—Å–∫", "–∏—Å–∫–∞—Ç—å", "–≥–¥–µ"]):
            query_type = "search"
        elif any(word in normalized_query.lower() for word in ["–¥–æ–±–∞–≤–∏—Ç—å", "—Å–æ–∑–¥–∞—Ç—å", "—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å"]):
            query_type = "create"
        elif any(word in normalized_query.lower() for word in ["–∏–∑–º–µ–Ω–∏—Ç—å", "–æ–±–Ω–æ–≤–∏—Ç—å", "–∏—Å–ø—Ä–∞–≤–∏—Ç—å"]):
            query_type = "update"

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –ò–ò –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞
        system_prompt = """–¢—ã - –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤. 
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –Ω–∞—Ö–æ–¥–∏—Ç—å, –¥–æ–±–∞–≤–ª—è—Ç—å –∏ –æ–±–Ω–æ–≤–ª—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–≤–∞—Ä–∞—Ö.
        
        –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –Ω–æ –≤ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–π –º–∞–Ω–µ—Ä–µ. –ò—Å–ø–æ–ª—å–∑—É–π —Å–º–∞–π–ª–∏–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏.
        
        –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–æ—Ö–æ–∂–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã.
        –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ—è—Å–µ–Ω, –∑–∞–¥–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã.
        
        –í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π –ø—Ä–∏—á–∏–Ω—É, –ø–æ—á–µ–º—É —Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å —Ç–æ—Ç –∏–ª–∏ –∏–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç."""

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò
        print("üîë –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á...")
        api_key = await get_api_key(db)
        if not api_key:
            print("‚ùå API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return {
                "message": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –ò–ò. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                "success": False
            }
        print("‚úÖ API –∫–ª—é—á –ø–æ–ª—É—á–µ–Ω")

        print("üåê –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –ò–ò...")
        async with aiohttp.ClientSession() as session:
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞: {query_type}\n–ó–∞–ø—Ä–æ—Å: {normalized_query}"}
            ]
            
            data = {
                "model": "gpt-4o-mini",
                "messages": messages,
                "temperature": 0.7,
                "max_tokens": 1000
            }
            
            async with session.post("https://api.polza.com/v1/chat/completions", headers=headers, json=data) as response:
                if response.status == 200:
                    result = await response.json()
                    ai_response = result["choices"][0]["message"]["content"]
                    
                    # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
                    if query_type == "search":
                        search_results = await smart_search_with_ai(normalized_query, db)
                        return {
                            "message": ai_response,
                            "search_results": search_results.get("matches", []),
                            "success": True
                        }
                    else:
                        return {
                            "message": ai_response,
                            "success": True
                        }
                else:
                    return {
                        "message": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞.",
                        "success": False
                    }
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return {
            "message": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å.",
            "success": False
        }

async def extract_articles_from_text(text: str, db: AsyncSession = None) -> List[dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—Ä—Ç–∏–∫—É–ª—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–æ–∫–∏ —á–µ—Ä–µ–∑ –ø–∞—Ä—Å–∏–Ω–≥ –∏ AI API"""
    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –ø–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–æ–∫—É –ª–æ–∫–∞–ª—å–Ω–æ
        lines = [line.strip() for line in text.strip().split('\n') if line.strip()]
        articles = []
        
        for line in lines:
            if len(line) > 4:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
                # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫—É
                parsed_item = parse_item_string(line)
                
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –∞—Ä—Ç–∏–∫—É–ª –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ, –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if parsed_item['agb_article'] or parsed_item['description']:
                    articles.append({
                        'agb_article': parsed_item['agb_article'],
                        'description': parsed_item['description'],
                        'quantity': parsed_item['quantity'],
                        'unit': parsed_item['unit']
                    })
        
        # –ï—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º AI
        if not articles:
            async with aiohttp.ClientSession() as session:
                prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –∏ –Ω–∞–π–¥–∏ –≤—Å–µ –∞—Ä—Ç–∏–∫—É–ª—ã —Ç–æ–≤–∞—Ä–æ–≤. 
–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å –º–∞—Å—Å–∏–≤–æ–º –æ–±—ä–µ–∫—Ç–æ–≤, –≥–¥–µ –∫–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç:
- "article": –Ω–∞–π–¥–µ–Ω–Ω—ã–π –∞—Ä—Ç–∏–∫—É–ª
- "description": –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
- "quantity": –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ)
- "unit": –µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞)

–¢–µ–∫—Å—Ç: {text}

–ï—Å–ª–∏ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ [].
"""
                
                payload = {
                    "model": "gpt-4o-mini",
                    "messages": [
                        {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–æ–≤–∞—Ä–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π. –ò–∑–≤–ª–µ–∫–∞–π –∞—Ä—Ç–∏–∫—É–ª—ã –∏ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞."},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.1
                }
                
                # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
                api_key = await get_api_key(db)
                if not api_key:
                    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á")
                    return []
                
                headers = {
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                }
                
                async with session.post(POLZA_API_URL, json=payload, headers=headers) as response:
                    if response.status == 200:
                        result = await response.json()
                        content = result["choices"][0]["message"]["content"]
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ markdown –±–ª–æ–∫–µ)
                        if "```json" in content:
                            json_start = content.find("```json") + 7
                            json_end = content.find("```", json_start)
                            content = content[json_start:json_end].strip()
                        elif "```" in content:
                            json_start = content.find("```") + 3
                            json_end = content.find("```", json_start)
                            content = content[json_start:json_end].strip()
                        
                        import json
                        articles = json.loads(content)
                        return articles if isinstance(articles, list) else []
                    else:
                        print(f"‚ùå –û—à–∏–±–∫–∞ AI API: {response.status}")
                        return []
        
        return articles
                    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—Ä—Ç–∏–∫—É–ª–æ–≤: {str(e)}")
        return []

def transliterate_to_latin(text: str) -> str:
    """–¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è —Ä—É—Å—Å–∫–∏—Ö –±—É–∫–≤ –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É"""
    translit_map = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'e',
        '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
        '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
        '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya',
        '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'E',
        '–ñ': 'Zh', '–ó': 'Z', '–ò': 'I', '–ô': 'Y', '–ö': 'K', '–õ': 'L', '–ú': 'M',
        '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T', '–£': 'U',
        '–§': 'F', '–•': 'H', '–¶': 'Ts', '–ß': 'Ch', '–®': 'Sh', '–©': 'Sch',
        '–™': '', '–´': 'Y', '–¨': '', '–≠': 'E', '–Æ': 'Yu', '–Ø': 'Ya'
    }
    
    result = text
    for ru_char, en_char in translit_map.items():
        result = result.replace(ru_char, en_char)
    
    result = result.lower()
    
    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
    result = result.replace(' ', '_').replace('-', '_').replace('.', '').replace(',', '').replace('(', '').replace(')', '')
    
    return result
from models import User, UserRole, ArticleMapping, ContractorRequest, ContractorRequestItem, MatchingNomenclature
from ..schemas import (
    ArticleMapping as ArticleMappingSchema,
    ArticleMappingCreate,
    ContractorRequest as ContractorRequestSchema,
    ContractorRequestCreate,
    ContractorRequestItem as ContractorRequestItemSchema,
    ContractorRequestItemCreate,
    ContractorRequestItemUpdate,
    MatchingResult,
    MatchingSummary,
    TextUploadRequest
)
from .auth import get_current_user

router = APIRouter()

@router.post("/chat/", response_model=dict)
async def chat_with_ai(
    message: dict,
    db: AsyncSession = Depends(get_db)
) -> dict:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ-—è–∑—ã–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ –ò–ò"""
    try:
        query = message.get("message", "").strip()
        if not query:
            return {
                "message": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å.",
                "success": False
            }
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
        response = await process_natural_language_query(query, db)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        log = AiProcessingLog(
            request_type="chat",
            input_text=query,
            ai_response=response.get("message", ""),
            status="success" if response.get("success") else "error",
            processing_time=time.time()
        )
        db.add(log)
        await db.commit()
        
        return response
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ —á–∞—Ç–µ —Å –ò–ò: {e}")
        return {
            "message": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            "success": False
        }

# URL –¥–ª—è Polza.ai
POLZA_API_URL = "https://api.polza.ai/v1/chat/completions"

async def get_api_key(db: AsyncSession) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–π API –∫–ª—é—á –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º Polza.ai –∫–ª—é—á
        result = await db.execute(select(ApiKey).where(
            ApiKey.is_active == True,
            ApiKey.provider == 'polza'
        ).limit(1))
        api_key_obj = result.scalar_one_or_none()
        
        # –ï—Å–ª–∏ Polza.ai –∫–ª—é—á–∞ –Ω–µ—Ç, –±–µ—Ä–µ–º OpenAI
        if not api_key_obj:
            result = await db.execute(select(ApiKey).where(
                ApiKey.is_active == True,
                ApiKey.provider == 'openai'
            ).limit(1))
            api_key_obj = result.scalar_one_or_none()
        
        if not api_key_obj:
            raise Exception("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ API –∫–ª—é—á–∞ –¥–ª—è –ò–ò-—Å–µ—Ä–≤–∏—Å–∞")
        
        # –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ–º –∫–ª—é—á
        try:
            from cryptography.fernet import Fernet
            import os
            ENCRYPTION_KEY = b'iF0d2ARGQpaU9GFfQdWNovBL239dqwTp9hDDPrDQQic='
            cipher_suite = Fernet(ENCRYPTION_KEY)
            decrypted_key = cipher_suite.decrypt(api_key_obj.key.encode()).decode()
        except Exception:
            # –í–æ–∑–º–æ–∂–Ω–æ, –∫–ª—é—á –Ω–µ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
            decrypted_key = api_key_obj.key
        
        return decrypted_key.strip()
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è API –∫–ª—é—á–∞: {e}")
        return ""


def normalize_ai_article(article: dict) -> dict:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –ò–ò"""
    normalized = {
        'contractor_article': None,
        'description': None,
        'quantity': 1,
        'unit': '—à—Ç',
        'agb_article': None,
        'bl_article': None,
        'match_confidence': 0.0,
        'match_type': 'unknown',
        'nomenclature': None
    }

    # –ï—Å–ª–∏ article - —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ (–Ω–∞—Ç—É—Ä–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å), –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–∏–µ
    if isinstance(article, str):
        description = article.strip()
        if description:
            # –ò—â–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –∞—Ä—Ç–∏–∫—É–ª –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
            parsed = parse_item_string(description)
            if parsed['agb_article']:
                normalized['contractor_article'] = parsed['agb_article']
                normalized['description'] = parsed['description']
                normalized['quantity'] = parsed['quantity']
                normalized['unit'] = parsed['unit']
            else:
                normalized['description'] = description
                normalized['contractor_article'] = None
        else:
            normalized['description'] = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä'
        return normalized

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∏–∑ –ò–ò –æ—Ç–≤–µ—Ç–∞
    if isinstance(article, dict):
        # contractor_article –º–æ–∂–µ—Ç –±—ã—Ç—å None, –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
        contractor_article = article.get('contractor_article')
        if contractor_article is not None and contractor_article != '':
            normalized['contractor_article'] = str(contractor_article).strip()
        elif not normalized['contractor_article']:
            # –ï—Å–ª–∏ contractor_article –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —á–∞—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è –∫–∞–∫ –∞—Ä—Ç–∏–∫—É–ª
            description = article.get('description', '')
            if description:
                # –ò—â–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –∞—Ä—Ç–∏–∫—É–ª –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
                parsed = parse_item_string(description)
                if parsed['agb_article']:
                    normalized['contractor_article'] = parsed['agb_article']
                    normalized['description'] = parsed['description'] or description
                else:
                    normalized['description'] = description
            else:
                normalized['description'] = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä'

        # –û–ø–∏—Å–∞–Ω–∏–µ
        description = article.get('description')
        if description:
            normalized['description'] = str(description).strip()
        elif not normalized['description']:
            normalized['description'] = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä'

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ –µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è
        quantity = article.get('quantity')
        if quantity is not None:
            try:
                normalized['quantity'] = int(quantity)
            except (ValueError, TypeError):
                normalized['quantity'] = 1

        unit = article.get('unit')
        if unit:
            normalized['unit'] = str(unit).strip()

        # –ê—Ä—Ç–∏–∫—É–ª—ã –ê–ì–ë –∏ BL
        agb_article = article.get('agb_article')
        if agb_article:
            normalized['agb_article'] = str(agb_article).strip()

        bl_article = article.get('bl_article')
        if bl_article:
            normalized['bl_article'] = str(bl_article).strip()

        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        confidence = article.get('match_confidence')
        if confidence is not None:
            try:
                normalized['match_confidence'] = float(confidence)
            except (ValueError, TypeError):
                normalized['match_confidence'] = 0.0

        # –¢–∏–ø —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        match_type = article.get('match_type')
        if match_type:
            normalized['match_type'] = str(match_type).strip()

    return normalized


def parse_item_string(item_string: str) -> dict:
    """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É —Ç–æ–≤–∞—Ä–∞ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∞—Ä—Ç–∏–∫—É–ª, –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ"""
    import re

    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    item_string = item_string.strip()

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ (–≤–µ–∑–¥–µ –≤ —Å—Ç—Ä–æ–∫–µ)
    article_patterns = [
        r'([A-Z–ê-–Ø]{2,6}[-_]\d{6,8})',    # –û–•–ö–£-000184, BL-123456
        r'([A-Z–ê-–Ø]{2,6}\d{6,8})',        # –û–•–ö–£000184, BL123456
        r'(\d{6,8})',                      # 123456
        r'([A-Z–ê-–Ø]{2,6}[-_]\d{3,8})',    # –û–•–ö–£-184, BL-123
        r'([A-Z–ê-–Ø]{3,6}[-_]\d{4,6})',    # BL-1234, –û–•–ö–£-1234
        r'(\d{4,6}[-_][A-Z–ê-–Ø]{2,4})',    # 1234-BL, 123456-–ê–ì–ë
        r'([A-Z–ê-–Ø]{1,3}\d{4,8})',        # B1234, BL123456
        r'(\d{4,8}[A-Z–ê-–Ø]{1,3})',        # 1234B, 123456BL
    ]

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞)
    quantity_patterns = [
        r'(\d+)\s*(—à—Ç|—à—Ç—É–∫|pcs|pieces?|–∫–≥|kg|–ª|l|–º|m|–º¬≤|–º¬≥)\s*$',  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏
        r'\((\d+)\s*(—à—Ç|—à—Ç—É–∫|pcs|pieces?|–∫–≥|kg|–ª|l|–º|m|–º¬≤|–º¬≥)\)',  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ —Å–∫–æ–±–∫–∞—Ö
        r'(\d+)\s*(—à—Ç|—à—Ç—É–∫|pcs|pieces?|–∫–≥|kg|–ª|l|–º|m|–º¬≤|–º¬≥)',      # –æ–±—â–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω
    ]

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª
    article = ""
    description = item_string
    quantity = 1
    unit = "—à—Ç"

    # –ò—â–µ–º –∞—Ä—Ç–∏–∫—É–ª –≤ –ª—é–±–æ–π —á–∞—Å—Ç–∏ —Å—Ç—Ä–æ–∫–∏ (–Ω–∞—á–∏–Ω–∞–µ–º —Å –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤)
    for pattern in article_patterns:
        matches = re.findall(pattern, item_string)
        if matches:
            # –ë–µ—Ä–µ–º —Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –∞—Ä—Ç–∏–∫—É–ª
            potential_articles = [m for m in matches if len(m) >= 3]
            if potential_articles:
                article = max(potential_articles, key=len)
                # –£–±–∏—Ä–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
                description = re.sub(re.escape(article), '', item_string).strip()
                # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
                description = re.sub(r'^[-_.,\s]+|[-_.,\s]+$', '', description)
                break
    
    # –ò—â–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è
    for pattern in quantity_patterns:
        match = re.search(pattern, item_string, re.IGNORECASE)
        if match:
            quantity = int(match.group(1))
            if len(match.groups()) > 1:
                unit = match.group(2).lower()
                if unit in ['pcs', 'pieces']:
                    unit = '—à—Ç'
                elif unit in ['kg']:
                    unit = '–∫–≥'
                elif unit in ['l']:
                    unit = '–ª'
                elif unit in ['m']:
                    unit = '–º'
            # –£–±–∏—Ä–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
            description = re.sub(pattern, '', description, flags=re.IGNORECASE).strip()
            break
    
    # –û—á–∏—â–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
    description = re.sub(r'\s+', ' ', description).strip()
    description = re.sub(r'^[-_\s]+', '', description)
    
    return {
        'agb_article': article,
        'description': description,
        'quantity': quantity,
        'unit': unit
    }

@router.post("/search/")
async def search_nomenclature(
    request: dict,
    db: AsyncSession = Depends(get_db)
) -> dict:
    """–ü–æ–∏—Å–∫ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏"""
    original_query = request.get("query", "").strip()
    search_type = request.get("search_type", "article")

    if not original_query:
        return {"matches": []}

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    normalized_query = get_normalized_text(original_query)
    print(f"–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: '{normalized_query}' (–±—ã–ª–æ: '{original_query}')")

    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    base_query = select(MatchingNomenclature).where(MatchingNomenclature.is_active == True)

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    result = await db.execute(base_query)
    all_items = result.scalars().all()

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —É—á–µ—Ç–æ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏
    matches = []
    for item in all_items:
        match_confidence = 0
        match_reason = ""

        if search_type == "article":
            # –î–ª—è –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            if item.agb_article and normalized_query.lower() in item.agb_article.lower():
                match_confidence = 100 if normalized_query.lower() == item.agb_article.lower() else 80
                match_reason = "–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É –ê–ì–ë"
            elif item.bl_article and normalized_query.lower() in item.bl_article.lower():
                match_confidence = 90 if normalized_query.lower() == item.bl_article.lower() else 70
                match_reason = "–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É BL"
        
        elif search_type == "name":
            # –î–ª—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
            normalized_name = get_normalized_text(item.name)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º
            if normalized_query.lower() == normalized_name.lower():
                match_confidence = 100
                match_reason = "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è"
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                query_words = set(normalized_query.lower().split())
                name_words = set(normalized_name.lower().split())
                
                # –ù–∞—Ö–æ–¥–∏–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞
                common_words = query_words & name_words
                
                if common_words:
                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                    match_confidence = int((len(common_words) / len(query_words)) * 100)
                    match_reason = "–ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è"
                
                # –ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∏–∑–∫–æ–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
                if match_confidence < 70:
                    similarity = calculate_similarity(normalized_query, normalized_name)
                    text_match_confidence = int(similarity * 100)
                    if text_match_confidence > match_confidence:
                        match_confidence = text_match_confidence
                        match_reason = "–°—Ö–æ–∂–µ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è"
        
        elif search_type == "code":
            # –î–ª—è –∫–æ–¥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            if item.code_1c and normalized_query.lower() in item.code_1c.lower():
                match_confidence = 100 if normalized_query.lower() == item.code_1c.lower() else 80
                match_reason = "–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–æ–¥—É 1–°"

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
        if match_confidence >= 50:
            matches.append({
                "id": item.id,
                "agb_article": item.agb_article,
                "name": item.name,
                "code_1c": item.code_1c,
                "bl_article": item.bl_article,
                "packaging": item.packaging,
                "unit": item.unit,
                "match_confidence": match_confidence,
                "match_reason": match_reason
            })

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    matches.sort(key=lambda x: x["match_confidence"], reverse=True)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    matches = matches[:20]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –∏—Å—Ç–æ—Ä–∏–∏
    chat_message = AIChatMessage(
        session_id=1,  # TODO: –ü–æ–ª—É—á–∞—Ç—å –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        message_type="system",
        content=f"–ü–æ–∏—Å–∫: {original_query} ‚Üí {normalized_query} (—Ç–∏–ø: {search_type})",
        search_query=original_query,
        search_type=search_type,
        matching_results=matches
    )
    db.add(chat_message)
    await db.commit()

    return {"matches": matches}

async def smart_search_with_ai(search_text: str, db: AsyncSession) -> dict:
    """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ AI - –ø–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É –∏ –∏—â–µ—Ç –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º"""
    try:
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        normalized_text = get_normalized_text(search_text)
        print(f"üîç –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞: '{search_text}' ‚Üí '{normalized_text}'")
        
        # –ü–∞—Ä—Å–∏–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        parsed_item = parse_item_string(normalized_text)
        
        print(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–∏: '{normalized_text}'")
        print(f"   –ê—Ä—Ç–∏–∫—É–ª: '{parsed_item['agb_article']}'")
        print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: '{parsed_item['description']}'")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {parsed_item['quantity']} {parsed_item['unit']}")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—é
        if parsed_item['agb_article'] or parsed_item['description']:
            print(f"üîç –ò—â–µ–º –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è—Ö...")
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            query = select(ArticleMapping).where(ArticleMapping.is_active == True)
            conditions = []
            
            if parsed_item['agb_article']:
                conditions.append(ArticleMapping.contractor_article.ilike(f"%{parsed_item['agb_article']}%"))
            
            if parsed_item['description']:
                conditions.append(ArticleMapping.contractor_description.ilike(f"%{parsed_item['description']}%"))
            
            if conditions:
                query = query.where(or_(*conditions)).limit(10)
                existing_mappings = await db.execute(query)
                mappings = existing_mappings.scalars().all()
                
                if mappings:
                    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(mappings)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π")
                    matches = []
                    for mapping in mappings:
                        confidence = 100 if mapping.contractor_article == parsed_item['agb_article'] else 90
                        matches.append({
                            "agb_article": mapping.agb_article,
                            "bl_article": mapping.bl_article,
                            "name": mapping.agb_description,
                            "code_1c": "",
                            "confidence": mapping.match_confidence or confidence,
                            "packaging": mapping.packaging_factor or 1,
                            "is_existing": True,
                            "mapping_id": mapping.id,
                            "contractor_article": mapping.contractor_article,
                            "match_reason": "–ù–∞–π–¥–µ–Ω–æ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è—Ö"
                        })
                    
                    return {
                        "search_type": "existing_mapping",
                        "matches": matches
                    }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–µ –∏ —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        print(f"üîç –ò—â–µ–º –≤ –±–∞–∑–µ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã...")
        matches = []
        
        # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–µ
        query = select(MatchingNomenclature).where(MatchingNomenclature.is_active == True)
        conditions = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–ª–æ–≤–∏—è –ø–æ–∏—Å–∫–∞
        if parsed_item['agb_article']:
            conditions.extend([
                MatchingNomenclature.agb_article.ilike(f"%{parsed_item['agb_article']}%"),
                MatchingNomenclature.bl_article.ilike(f"%{parsed_item['agb_article']}%"),
                MatchingNomenclature.code_1c.ilike(f"%{parsed_item['agb_article']}%")
            ])
        
        if parsed_item['description']:
            conditions.append(MatchingNomenclature.name.ilike(f"%{parsed_item['description']}%"))
        
        if conditions:
            query = query.where(or_(*conditions)).limit(20)
            result = await db.execute(query)
            found_items = result.scalars().all()
            
            for item in found_items:
                confidence = 0
                match_reason = ""
                
                # –í—ã—á–∏—Å–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                if parsed_item['agb_article']:
                    if item.agb_article and item.agb_article.lower() == parsed_item['agb_article'].lower():
                        confidence = 100
                        match_reason = "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É –ê–ì–ë"
                    elif item.bl_article and item.bl_article.lower() == parsed_item['agb_article'].lower():
                        confidence = 95
                        match_reason = "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É BL"
                    elif item.code_1c and item.code_1c.lower() == parsed_item['agb_article'].lower():
                        confidence = 90
                        match_reason = "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–æ–¥—É 1–°"
                    else:
                        # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                        confidence = 70
                        match_reason = "–ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É"
                
                if parsed_item['description'] and confidence < 100:
                    desc_similarity = calculate_similarity(parsed_item['description'], item.name)
                    if desc_similarity > 0.8:
                        confidence = max(confidence, 85)
                        match_reason = "–í—ã—Å–æ–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è"
                    elif desc_similarity > 0.6:
                        confidence = max(confidence, 75)
                        match_reason = "–°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è"
                
                if confidence > 0:
                    matches.append({
                        "agb_article": item.agb_article,
                        "bl_article": item.bl_article,
                        "name": item.name,
                        "code_1c": item.code_1c,
                        "confidence": confidence,
                        "match_reason": match_reason,
                        "is_existing": False
                    })

        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –±–∞–∑–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Ö
        if matches:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(matches)} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ –±–∞–∑–µ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã")
            return {
                "search_type": "database_match",
                "matches": matches
            }

        print(f"‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ –±–∞–∑–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ò–ò")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ò–ò –¥–ª—è –ø–æ–∏—Å–∫–∞
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            all_nomenclatures = await db.execute(
                select(MatchingNomenclature).where(MatchingNomenclature.is_active == True).limit(100)
            )
            nomenclatures = all_nomenclatures.scalars().all()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞–º–∏ –¥–ª—è –ò–ò
            nomenclatures_text = "\n".join([
                f"- {nom.agb_article} | {nom.bl_article or 'N/A'} | {nom.name}"
                for nom in nomenclatures
            ])
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –ò–ò
            prompt = f"""–ù–∞–π–¥–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä –ø–æ –∑–∞–ø—Ä–æ—Å—É: "{search_text}"

–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤:
{nomenclatures_text}

–í–µ—Ä–Ω–∏ JSON –º–∞—Å—Å–∏–≤ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
[
    {{
        "agb_article": "–∞—Ä—Ç–∏–∫—É–ª –ê–ì–ë",
        "bl_article": "–∞—Ä—Ç–∏–∫—É–ª BL",
        "name": "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ",
        "code_1c": "–∫–æ–¥ 1–°",
        "confidence": 85,
        "match_reason": "–ø—Ä–∏—á–∏–Ω–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
    }}
]

–ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤: []"""

            # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á
            api_key = await get_api_key(db)
            if not api_key:
                return {"search_type": "error", "matches": []}

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –ò–ò
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                }
                
                data = {
                    "model": "gpt-4o-mini",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.1,
                    "max_tokens": 1500
                }
                
                async with session.post("https://api.polza.com/v1/chat/completions", headers=headers, json=data) as response:
                    if response.status in [200, 201]:
                        result = await response.json()
                        ai_response = result["choices"][0]["message"]["content"]
                        
                        # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
                        import json
                        try:
                            if "```json" in ai_response:
                                json_start = ai_response.find("```json") + 7
                                json_end = ai_response.find("```", json_start)
                                ai_response = ai_response[json_start:json_end].strip()
                            elif "```" in ai_response:
                                json_start = ai_response.find("```") + 3
                                json_end = ai_response.find("```", json_start)
                                ai_response = ai_response[json_start:json_end].strip()

                            matches = json.loads(ai_response)
                            if isinstance(matches, list) and matches:
                                print(f"‚úÖ –ò–ò –Ω–∞—à–µ–ª {len(matches)} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
                                return {
                                    "search_type": "ai_match",
                                    "matches": matches
                                }
                        except json.JSONDecodeError:
                            pass
            
            # –ï—Å–ª–∏ –ò–ò –Ω–µ –Ω–∞—à–µ–ª –Ω–∏—á–µ–≥–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return {"search_type": "not_found", "matches": []}
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ò–ò –ø–æ–∏—Å–∫–∞: {e}")
            return {"search_type": "error", "matches": []}

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä –¥–ª—è AI —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—é
        relevant_nomenclatures = []
        search_terms = [parsed_item['agb_article'], parsed_item['description']]
        search_terms = [term.lower() for term in search_terms if term]

        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã
        for nom in nomenclatures:
            relevance_score = 0

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä—Ç–∏–∫—É–ª –ê–ì–ë
            if parsed_item['agb_article'] and nom.agb_article:
                if parsed_item['agb_article'].lower() in nom.agb_article.lower():
                    relevance_score += 100
                elif nom.agb_article.lower() in parsed_item['agb_article'].lower():
                    relevance_score += 80

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä—Ç–∏–∫—É–ª BL
            if parsed_item['agb_article'] and nom.bl_article:
                if parsed_item['agb_article'].lower() in nom.bl_article.lower():
                    relevance_score += 90
                elif nom.bl_article.lower() in parsed_item['agb_article'].lower():
                    relevance_score += 70

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥ 1–°
            if parsed_item['agb_article'] and nom.code_1c:
                if parsed_item['agb_article'].lower() in nom.code_1c.lower():
                    relevance_score += 60

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ
            if parsed_item['description'] and nom.name:
                if parsed_item['description'].lower() in nom.name.lower():
                    relevance_score += 50
                elif nom.name.lower() in parsed_item['description'].lower():
                    relevance_score += 40

            if relevance_score > 0:
                relevant_nomenclatures.append((nom, relevance_score))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        relevant_nomenclatures.sort(key=lambda x: x[1], reverse=True)

        # –ë–µ—Ä–µ–º —Ç–æ–ø-100 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö + 100 —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        top_relevant = relevant_nomenclatures[:100]
        remaining_count = min(100, len(nomenclatures) - len(top_relevant))

        import random
        random_nomenclatures = random.sample(
            [nom for nom, score in relevant_nomenclatures[100:] if nom not in [n for n, s in top_relevant]],
            remaining_count
        ) if len(nomenclatures) > len(top_relevant) else []

        selected_nomenclatures = [nom for nom, score in top_relevant] + random_nomenclatures

        print(f"üìä –í—ã–±—Ä–∞–Ω–æ –¥–ª—è –ø–æ–∏—Å–∫–∞: {len(selected_nomenclatures)} –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö: {len(top_relevant)}, —Å–ª—É—á–∞–π–Ω—ã—Ö: {len(random_nomenclatures)})")

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä –¥–ª—è AI
        nomenclatures_text = "\n".join([
            f"ID: {nom.id}, –ê–ì–ë: {nom.agb_article}, BL: {nom.bl_article or '–Ω–µ—Ç'}, –ö–æ–¥1–°: {nom.code_1c or '–Ω–µ—Ç'}, –ù–∞–∑–≤–∞–Ω–∏–µ: {nom.name}, –§–∞—Å–æ–≤–∫–∞: {nom.packaging or 1}, –ï–¥: {nom.unit}"
            for nom in selected_nomenclatures[:200]
        ])
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è AI —Å —É—á–µ—Ç–æ–º –ø–∞—Ä—Å–∏–Ω–≥–∞
        prompt = f"""
        –¢–´ - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–∏—Å–∫—É —Ç–æ–≤–∞—Ä–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –ê–ì–ë.

        –ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: "{search_text}"

        –ü–†–û–ê–ù–ê–õ–ò–ó–ò–†–£–ô –ó–ê–ü–†–û–° –ò –ù–ê–ô–î–ò –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø –í –ë–ê–ó–ï –î–ê–ù–ù–´–•:
        {nomenclatures_text}

        –ü–†–ê–í–ò–õ–ê:
        - –ò—â–∏ –¢–û–ß–ù–´–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º —Ç–æ–≤–∞—Ä–æ–≤
        - –°—Ä–∞–≤–Ω–∏–≤–∞–π —Å–ª–æ–≤–∞ –∏ —Ñ—Ä–∞–∑—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –≤ –±–∞–∑–µ
        - –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–µ—Ç, –∏—â–∏ –ø–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã (—Å—Ö–æ–∂–µ—Å—Ç—å > 70%)
        - –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

        –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (JSON):
        {{
            "search_type": "ai_match",
            "matches": [
                {{
                    "id": "ID_–∏–∑_–±–∞–∑—ã",
                    "agb_article": "–∞—Ä—Ç–∏–∫—É–ª_–ê–ì–ë",
                    "bl_article": "–∞—Ä—Ç–∏–∫—É–ª_BL_–∏–ª–∏_null",
                    "code_1c": "–∫–æ–¥_1–°_–∏–ª–∏_null",
                    "name": "–Ω–∞–∑–≤–∞–Ω–∏–µ_—Ç–æ–≤–∞—Ä–∞",
                    "confidence": 75,
                    "match_reason": "–Ω–∞–π–¥–µ–Ω–æ_–ø–æ_–Ω–∞–∑–≤–∞–Ω–∏—é"
                }}
            ]
        }}

        –ï–°–õ–ò –ù–ò–ß–ï–ì–û –ù–ï –ù–ê–ô–î–ï–ù–û - –≤–µ—Ä–Ω–∏: {{"search_type": "ai_match", "matches": []}}
        """
        
        # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        api_key = await get_api_key(db)
        if not api_key:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á")
            return {"search_type": "general", "matches": []}
        
        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ AI API
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                }
                
                data = {
                    "model": "gpt-4o-mini",
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.1,
                    "max_tokens": 1500
                }
                
                try:
                    async with session.post(POLZA_API_URL, headers=headers, json=data) as response:
                        if response.status in [200, 201]:
                            result = await response.json()
                            ai_response = result["choices"][0]["message"]["content"]
                            
                            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
                            import json
                            try:
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ markdown –±–ª–æ–∫–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                                if "```json" in ai_response:
                                    json_start = ai_response.find("```json") + 7
                                    json_end = ai_response.find("```", json_start)
                                    if json_end != -1:
                                        ai_response = ai_response[json_start:json_end].strip()
                                elif "```" in ai_response:
                                    json_start = ai_response.find("```") + 3
                                    json_end = ai_response.find("```", json_start)
                                    if json_end != -1:
                                        ai_response = ai_response[json_start:json_end].strip()

                                # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç "–ù–ò–ß–ï–ì–û –ù–ï –ù–ê–ô–î–ï–ù–û", –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                                if "–ù–ò–ß–ï–ì–û –ù–ï –ù–ê–ô–î–ï–ù–û" in ai_response.upper() or len(ai_response.strip()) < 10:
                                    return {"search_type": "ai_match", "matches": []}

                                matches = json.loads(ai_response)
                                ai_matches = matches.get('matches', [])
                                print(f"‚úÖ AI –Ω–∞—à–µ–ª {len(ai_matches)} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
                                return matches
                            except json.JSONDecodeError as e:
                                print(f"Failed to parse AI response: {e}")
                                print(f"AI response: {ai_response}")
                                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                                if ai_response and "–Ω–∞–π–¥–µ–Ω" in ai_response.lower() and len(ai_response) < 100:
                                    return {"search_type": "ai_match", "matches": []}
                                return {"search_type": "general", "matches": []}
                        else:
                            print(f"AI API error: {response.status}")
                            return {"search_type": "general", "matches": []}
                except Exception as e:
                    print(f"HTTP request error: {e}")
                    return {"search_type": "error", "matches": []}
        except Exception as e:
            print(f"AI search error: {e}")
            # –°–æ–∑–¥–∞–µ–º fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–º —Ç–æ–≤–∞—Ä–µ
            return {
                "search_type": "not_found",
                "matches": [{
                    "id": "0",
                    "agb_article": "",
                    "bl_article": "",
                    "code_1c": "",
                    "name": f"–¢–æ–≤–∞—Ä '{search_text}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö",
                    "confidence": 0.0,
                    "match_reason": "—Ç–æ–≤–∞—Ä_–Ω–µ_–Ω–∞–π–¥–µ–Ω"
                }]
            }

    except Exception as e:
        print(f"Global error: {e}")
        return {"search_type": "error", "matches": []}


async def search_with_ai(description: str, db: AsyncSession) -> dict:
    """–ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ AI API (—Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
    result = await smart_search_with_ai(description, db)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    return {"matches": result.get("matches", [])}


def calculate_similarity(text1: str, text2: str) -> float:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏"""
    return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()


def find_best_match(description: str, nomenclature_list: List[MatchingNomenclature]) -> Optional[tuple]:
    """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞"""
    best_match = None
    best_score = 0.0
    
    for nomenclature in nomenclature_list:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
        name_score = calculate_similarity(description, nomenclature.name)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É
        article_score = calculate_similarity(description, nomenclature.agb_article)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫–∏
        combined_score = max(name_score, article_score * 0.8)  # –ê—Ä—Ç–∏–∫—É–ª –º–µ–Ω–µ–µ –≤–∞–∂–µ–Ω
        
        if combined_score > best_score and combined_score > 0.3:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
            best_score = combined_score
            best_match = nomenclature
    
    if best_match:
        return best_match, int(best_score * 100)
    return None


@router.get("/mappings/", response_model=List[ArticleMappingSchema])
async def get_article_mappings(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –∞—Ä—Ç–∏–∫—É–ª–æ–≤"""
    if current_user.role not in [UserRole.ADMIN, UserRole.VED_PASSPORT]:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    result = await db.execute(
        select(ArticleMapping)
        .where(ArticleMapping.is_active == True)
        .order_by(ArticleMapping.created_at.desc())
    )
    mappings = result.scalars().all()
    return mappings


@router.post("/mappings/", response_model=ArticleMappingSchema)
async def create_article_mapping(
    mapping_data: ArticleMappingCreate,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∞—Ä—Ç–∏–∫—É–ª–æ–≤"""
    if current_user.role not in [UserRole.ADMIN, UserRole.VED_PASSPORT]:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    try:
        new_mapping = ArticleMapping(
            contractor_article=mapping_data.contractor_article,
            contractor_description=mapping_data.contractor_description,
            agb_article=mapping_data.agb_article,
            agb_description=mapping_data.agb_description,
            bl_article=mapping_data.bl_article,
            bl_description=mapping_data.bl_description,
            packaging_factor=mapping_data.packaging_factor,
            unit=mapping_data.unit,
            nomenclature_id=mapping_data.nomenclature_id
        )
        
        db.add(new_mapping)
        await db.commit()
        await db.refresh(new_mapping)
        
        return new_mapping
        
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {str(e)}")


@router.delete("/mappings/{mapping_id}/", response_model=dict)
async def delete_article_mapping(
    mapping_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–£–¥–∞–ª–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∞—Ä—Ç–∏–∫—É–ª–æ–≤"""
    if current_user.role not in [UserRole.ADMIN, UserRole.VED_PASSPORT]:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    try:
        # –ù–∞—Ö–æ–¥–∏–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        result = await db.execute(
            select(ArticleMapping).where(ArticleMapping.id == mapping_id)
        )
        mapping = result.scalar_one_or_none()
        
        if not mapping:
            raise HTTPException(status_code=404, detail="–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # –ú—è–≥–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ - –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ–µ
        mapping.is_active = False
        await db.commit()
        
        return {"message": "–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ", "success": True}
        
    except HTTPException:
        raise
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: {str(e)}")


@router.post("/requests/", response_model=ContractorRequestSchema)
async def create_contractor_request(
    request_data: ContractorRequestCreate,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∑–∞—è–≤–∫–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞"""
    if current_user.role not in [UserRole.ADMIN, UserRole.VED_PASSPORT]:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –Ω–æ–º–µ—Ä–∞ –∑–∞—è–≤–∫–∏
        existing = await db.execute(
            select(ContractorRequest).where(ContractorRequest.request_number == request_data.request_number)
        )
        if existing.scalar_one_or_none():
            raise HTTPException(status_code=400, detail="–ó–∞—è–≤–∫–∞ —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        
        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
        request_date = datetime.fromisoformat(request_data.request_date.replace('Z', '+00:00'))
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞—è–≤–∫—É
        new_request = ContractorRequest(
            request_number=request_data.request_number,
            contractor_name=request_data.contractor_name,
            request_date=request_date,
            total_items=len(request_data.items),
            created_by=current_user.id
        )
        
        db.add(new_request)
        await db.flush()  # –ü–æ–ª—É—á–∞–µ–º ID –∑–∞—è–≤–∫–∏
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –∑–∞—è–≤–∫–∏
        for item_data in request_data.items:
            new_item = ContractorRequestItem(
                request_id=new_request.id,
                line_number=item_data.line_number,
                contractor_article=item_data.contractor_article,
                description=item_data.description,
                unit=item_data.unit,
                quantity=item_data.quantity,
                category=item_data.category
            )
            db.add(new_item)
        
        await db.commit()
        await db.refresh(new_request)
        
        return new_request
        
    except HTTPException:
        raise
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞—è–≤–∫–∏: {str(e)}")


@router.get("/requests/", response_model=List[ContractorRequestSchema])
async def get_contractor_requests(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∑–∞—è–≤–æ–∫ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤"""
    if current_user.role not in [UserRole.ADMIN, UserRole.VED_PASSPORT]:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    result = await db.execute(
        select(ContractorRequest)
        .where(ContractorRequest.created_by == current_user.id)
        .order_by(ContractorRequest.created_at.desc())
    )
    requests = result.scalars().all()
    return requests


@router.get("/requests/{request_id}", response_model=ContractorRequestSchema)
async def get_contractor_request(
    request_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞—è–≤–∫–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞"""
    if current_user.role not in [UserRole.ADMIN, UserRole.VED_PASSPORT]:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    result = await db.execute(
        select(ContractorRequest)
        .where(ContractorRequest.id == request_id)
    )
    request = result.scalar_one_or_none()
    
    if not request:
        raise HTTPException(status_code=404, detail="–ó–∞—è–≤–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    if request.created_by != current_user.id:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    return request


@router.post("/requests/{request_id}/match", response_model=MatchingSummary)
async def match_articles(
    request_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –≤ –∑–∞—è–≤–∫–µ"""
    if current_user.role not in [UserRole.ADMIN, UserRole.VED_PASSPORT]:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞—è–≤–∫—É
        result = await db.execute(
            select(ContractorRequest).where(ContractorRequest.id == request_id)
        )
        request = result.scalar_one_or_none()
        
        if not request:
            raise HTTPException(status_code=404, detail="–ó–∞—è–≤–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        if request.created_by != current_user.id:
            raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –∑–∞—è–≤–∫–∏
        items_result = await db.execute(
            select(ContractorRequestItem)
            .where(ContractorRequestItem.request_id == request_id)
            .order_by(ContractorRequestItem.line_number)
        )
        items = items_result.scalars().all()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å—é –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—É –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        nomenclature_result = await db.execute(
            select(MatchingNomenclature).where(MatchingNomenclature.is_active == True)
        )
        nomenclature_list = nomenclature_result.scalars().all()
        
        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∂–¥—É—é –ø–æ–∑–∏—Ü–∏—é
        results = []
        matched_count = 0
        high_confidence = 0
        medium_confidence = 0
        low_confidence = 0
        
        for item in items:
            match_result = find_best_match(item.description, nomenclature_list)
            
            if match_result:
                nomenclature, confidence = match_result
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é
                item.matched_nomenclature_id = nomenclature.id
                item.agb_article = nomenclature.agb_article
                item.packaging_factor = 1  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                item.recalculated_quantity = item.quantity * item.packaging_factor
                item.match_confidence = confidence
                item.match_status = "matched"
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if confidence >= 80:
                    high_confidence += 1
                elif confidence >= 60:
                    medium_confidence += 1
                else:
                    low_confidence += 1
                
                matched_count += 1
                
                results.append(MatchingResult(
                    item_id=item.id,
                    contractor_article=item.contractor_article,
                    description=item.description,
                    matched=True,
                    agb_article=nomenclature.agb_article,
                    packaging_factor=item.packaging_factor,
                    recalculated_quantity=item.recalculated_quantity,
                    match_confidence=confidence,
                    nomenclature=nomenclature
                ))
            else:
                item.match_status = "unmatched"
                results.append(MatchingResult(
                    item_id=item.id,
                    contractor_article=item.contractor_article,
                    description=item.description,
                    matched=False
                ))
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞—è–≤–∫–∏
        request.matched_items = matched_count
        request.status = "processing"
        request.processed_by = current_user.id
        request.processed_at = datetime.now()
        
        await db.commit()
        
        return MatchingSummary(
            total_items=len(items),
            matched_items=matched_count,
            unmatched_items=len(items) - matched_count,
            high_confidence_items=high_confidence,
            medium_confidence_items=medium_confidence,
            low_confidence_items=low_confidence,
            results=results
        )
        
    except HTTPException:
        raise
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {str(e)}")


@router.put("/items/{item_id}", response_model=ContractorRequestItemSchema)
async def update_request_item(
    item_id: int,
    item_data: ContractorRequestItemUpdate,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –∑–∞—è–≤–∫–∏"""
    if current_user.role not in [UserRole.ADMIN, UserRole.VED_PASSPORT]:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–∑–∏—Ü–∏—é
        result = await db.execute(
            select(ContractorRequestItem).where(ContractorRequestItem.id == item_id)
        )
        item = result.scalar_one_or_none()
        
        if not item:
            raise HTTPException(status_code=404, detail="–ü–æ–∑–∏—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ —á–µ—Ä–µ–∑ –∑–∞—è–≤–∫—É
        request_result = await db.execute(
            select(ContractorRequest).where(ContractorRequest.id == item.request_id)
        )
        request = request_result.scalar_one_or_none()
        
        if not request or request.created_by != current_user.id:
            raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è
        update_data = item_data.model_dump(exclude_unset=True)
        for field, value in update_data.items():
            setattr(item, field, value)
        
        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª—Å—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ñ–∞—Å–æ–≤–∫–∏
        if item_data.packaging_factor is not None:
            item.recalculated_quantity = item.quantity * item.packaging_factor
        
        await db.commit()
        await db.refresh(item)
        
        return item
        
    except HTTPException:
        raise
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø–æ–∑–∏—Ü–∏–∏: {str(e)}")


@router.post("/upload-excel/", response_model=ContractorRequestSchema)
async def upload_contractor_excel(
    file: UploadFile = File(...),
    contractor_name: str = "–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç",
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞—è–≤–∫–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ –∏–∑ Excel —Ñ–∞–π–ª–∞"""
    if current_user.role not in [UserRole.ADMIN, UserRole.VED_PASSPORT]:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    try:
        # –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª
        content = await file.read()
        df = pd.read_excel(io.BytesIO(content))
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–º–µ—Ä –∑–∞—è–≤–∫–∏
        request_number = f"REQ_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞—è–≤–∫—É
        new_request = ContractorRequest(
            request_number=request_number,
            contractor_name=contractor_name,
            request_date=datetime.now(),
            total_items=len(df),
            created_by=current_user.id
        )
        
        db.add(new_request)
        await db.flush()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ Excel
        items = []
        for index, row in df.iterrows():
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç—Ä–æ–∫–∏ (–∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–¥ —Ñ–æ—Ä–º–∞—Ç –∏–∑ –ø—Ä–∏–º–µ—Ä–∞)
            line_number = index + 1
            contractor_article = str(row.get('–ê—Ä—Ç–∏–∫—É–ª', row.get('‚Ññ', ''))).strip()
            description = str(row.get('–û–ø–∏—Å–∞–Ω–∏–µ', row.get('–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', ''))).strip()
            unit = str(row.get('–ï–¥.', row.get('–ï–¥–∏–Ω–∏—Ü–∞', '—à—Ç'))).strip()
            quantity = int(row.get('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', row.get('–ö–æ–ª-–≤–æ', 1)))
            category = str(row.get('–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–î–ª—è –±—É—Ä–µ–Ω–∏—è')).strip()
            
            if contractor_article and description:
                new_item = ContractorRequestItem(
                    request_id=new_request.id,
                    line_number=line_number,
                    contractor_article=contractor_article,
                    description=description,
                    unit=unit,
                    quantity=quantity,
                    category=category
                )
                db.add(new_item)
                items.append(new_item)
        
        await db.commit()
        await db.refresh(new_request)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        matching_results = await perform_matching(new_request.id, db)
        
        return {
            "request": new_request,
            "matching_results": matching_results
        }
        
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")


@router.post("/test-create-request/")
async def test_create_request(
    request_data: dict,
    db: AsyncSession = Depends(get_db)
):
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–∫–∏ –±–µ–∑ —Ñ–∞–π–ª–∞"""
    try:
        contractor_name = request_data.get("contractor_name", "–¢–µ—Å—Ç –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç")
        print(f"–ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –∑–∞—è–≤–∫–∏ –¥–ª—è: {contractor_name}")
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–º–µ—Ä –∑–∞—è–≤–∫–∏
        request_number = f"TEST_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        print(f"–ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏: {request_number}")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞—è–≤–∫—É
        new_request = ContractorRequest(
            request_number=request_number,
            contractor_name=contractor_name,
            request_date=datetime.now(),
            total_items=5,  # –¢–µ—Å—Ç–æ–≤–∞—è –∑–∞—è–≤–∫–∞ –∏–∑ 5 –ø–æ–∑–∏—Ü–∏–π
            created_by=1  # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        )
        print(f"–°–æ–∑–¥–∞–Ω–∞ –∑–∞—è–≤–∫–∞: {new_request}")
        
        db.add(new_request)
        await db.flush()
        print(f"–ó–∞—è–≤–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –ë–î, ID: {new_request.id}")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞—è–≤–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–º–µ—Ä–∞
        test_items = [
            {"agb_article": "1299650", "description": "–®–ø–∏–Ω–¥–µ–ª—å –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ –∫–µ—Ä–Ω–æ–ø—Ä–∏–µ–º–Ω–∏–∫–∞ H/HU, 25231, SDT", "quantity": 5, "unit": "—à—Ç"},
            {"agb_article": "1298240", "description": "–í—Ç—É–ª–∫–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è –∂–∏–¥–∫–æ—Å—Ç–∏ 306131, SDT", "quantity": 12, "unit": "—à—Ç"},
            {"agb_article": "1298244", "description": "–ü—Ä—É–∂–∏–Ω–∞ –º—è–≥–∫–∞—è N/H/P, —É–¥–µ—Ä–∂–∞–Ω–∏—è –∂–∏–¥–∫–æ—Å—Ç–∏, 104966, SDT", "quantity": 10, "unit": "—à—Ç"},
            {"agb_article": "1299679", "description": "–©–µ–∫–∞ –≤–µ—Ä—Ö–Ω—è—è –¥–ª—è –∫–ª—é—á–∞ —Ä–∞–∑–≤–æ–¥–Ω–æ–≥–æ 24\", 14947, SDT", "quantity": 8, "unit": "—à—Ç"},
            {"agb_article": "1299680", "description": "–©–µ–∫–∞ –≤–µ—Ä—Ö–Ω—è—è –¥–ª—è –∫–ª—é—á–∞ —Ä–∞–∑–≤–æ–¥–Ω–æ–≥–æ 36\", 14950, SDT", "quantity": 8, "unit": "—à—Ç"}
        ]
        
        items = []
        for index, item_data in enumerate(test_items):
            line_number = index + 1
            new_item = ContractorRequestItem(
                request_id=new_request.id,
                line_number=line_number,
                contractor_article=item_data["agb_article"],
                description=item_data["description"],
                unit=item_data["unit"],
                quantity=item_data["quantity"],
                category="–î–ª—è –±—É—Ä–µ–Ω–∏—è"
            )
            db.add(new_item)
            items.append(new_item)
        
        await db.commit()
        await db.refresh(new_request)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        matching_results = await perform_matching(new_request.id, db)
        
        return {
            "request": new_request,
            "matching_results": matching_results
        }
        
    except Exception as e:
        await db.rollback()
        import traceback
        error_details = traceback.format_exc()
        print(f"–û—à–∏–±–∫–∞ –≤ test_create_request: {str(e)}")
        print(f"Traceback: {error_details}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞—è–≤–∫–∏: {str(e)}")


@router.get("/requests/{request_id}/export/excel")
async def export_matching_results(
    request_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤ Excel"""
    if current_user.role not in [UserRole.ADMIN, UserRole.VED_PASSPORT]:
        raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞—è–≤–∫—É
        result = await db.execute(
            select(ContractorRequest).where(ContractorRequest.id == request_id)
        )
        request = result.scalar_one_or_none()
        
        if not request or request.created_by != current_user.id:
            raise HTTPException(status_code=403, detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ —Å –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–æ–π
        items_result = await db.execute(
            select(ContractorRequestItem)
            .options(selectinload(ContractorRequestItem.matched_nomenclature))
            .where(ContractorRequestItem.request_id == request_id)
            .order_by(ContractorRequestItem.line_number)
        )
        items = items_result.scalars().all()
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        data = []
        for item in items:
            data.append({
                '–ù–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏': item.line_number,
                '–ê—Ä—Ç–∏–∫—É–ª –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞': item.contractor_article,
                '–û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞': item.description,
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': item.quantity,
                '–ï–¥–∏–Ω–∏—Ü–∞': item.unit,
                '–°—Ç–∞—Ç—É—Å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è': item.match_status,
                '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (%)': item.match_confidence,
                '–ê—Ä—Ç–∏–∫—É–ª –ê–ì–ë': item.agb_article or '',
                '–ê—Ä—Ç–∏–∫—É–ª BL': item.bl_article or '',
                '–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ñ–∞—Å–æ–≤–∫–∏': item.packaging_factor,
                '–ü–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ': item.recalculated_quantity or item.quantity,
                '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞ –ê–ì–ë': item.matched_nomenclature.name if item.matched_nomenclature else '',
                '–ö–æ–¥ 1–°': item.matched_nomenclature.code_1c if item.matched_nomenclature else ''
            })
        
        df = pd.DataFrame(data)
        
        # –°–æ–∑–¥–∞–µ–º Excel —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è', index=False)
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–æ–∫
            worksheet = writer.sheets['–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è']
            for column in worksheet.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = (max_length + 2)
                worksheet.column_dimensions[column_letter].width = min(adjusted_width, 50)
        
        output.seek(0)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∞–π–ª
        from fastapi import Response
        return Response(
            content=output.getvalue(),
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            headers={
                'Content-Disposition': f'attachment; filename=matching_results_{request.request_number}.xlsx'
            }
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ: {str(e)}")


@router.post("/upload-text/")
async def upload_text_request(
    request_data: TextUploadRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞—è–≤–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å AI –ø–æ–∏—Å–∫–æ–º"""
    try:
        # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π
        items = parse_text_to_items(request_data.text)
        
        if not items:
            raise HTTPException(status_code=400, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞—è–≤–∫—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –Ω–æ–º–µ—Ä–æ–º
        contractor_name = request_data.contractor_name
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–º–µ—Ä –∑–∞—è–≤–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ {–Ω–∞–∑–≤–∞–Ω–∏–µ_–∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞}_{–ø–æ—Ä—è–¥–∫–æ–≤—ã–π_–Ω–æ–º–µ—Ä}_{–¥–∞—Ç–∞}
        contractor_name_latin = transliterate_to_latin(contractor_name)
        print(f"üî§ –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è: '{contractor_name}' -> '{contractor_name_latin}'")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞—è–≤–æ–∫ –¥–ª—è —ç—Ç–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ —Å–µ–≥–æ–¥–Ω—è
        today = datetime.now().date()
        count_result = await db.execute(
            select(func.count(ContractorRequest.id)).where(
                ContractorRequest.contractor_name == contractor_name,
                func.date(ContractorRequest.request_date) == today
            )
        )
        request_count = count_result.scalar() + 1
        
        request_number = f"{contractor_name_latin}_{request_count:03d}_{datetime.now().strftime('%Y%m%d')}"
        
        request = ContractorRequest(
            request_number=request_number,
            contractor_name=contractor_name,
            request_date=datetime.now(),
            total_items=len(items),
            status='new',
            created_by=current_user.id
        )
        
        db.add(request)
        await db.flush()  # –ü–æ–ª—É—á–∞–µ–º ID –∑–∞—è–≤–∫–∏
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –∑–∞—è–≤–∫–∏ —Å AI –ø–æ–∏—Å–∫–æ–º
        for item_data in items:
            description = item_data.get('description', '')
            print(f"Searching AI matches for: {description}")
            
            # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —á–µ—Ä–µ–∑ AI
            ai_matches = await search_with_ai(description, db)
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ–∑–∏—Ü–∏—é –∑–∞—è–≤–∫–∏
            item = ContractorRequestItem(
                request_id=request.id,
                contractor_article=item_data.get('agb_article', ''),
                description=description,
                quantity=item_data.get('quantity', 1),
                unit=item_data.get('unit', '—à—Ç')
            )
            db.add(item)
            await db.flush()  # –ü–æ–ª—É—á–∞–µ–º ID –ø–æ–∑–∏—Ü–∏–∏
            
            # –ï—Å–ª–∏ AI –Ω–∞—à–µ–ª —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è, —Å–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            if ai_matches.get('matches'):
                for match in ai_matches['matches']:
                    # –ò—â–µ–º –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—É –≤ –±–∞–∑–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É
                    nom_result = await db.execute(
                        select(MatchingNomenclature).where(MatchingNomenclature.agb_article == match['agb_article'])
                    )
                    nomenclature = nom_result.scalar_one_or_none()
                    
                    if nomenclature:
                        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
                        mapping = ArticleMapping(
                            contractor_request_item_id=item.id,
                            agb_article=match['agb_article'],
                            bl_article=match.get('code_1c', ''),
                            match_confidence=match.get('confidence', 0.0),
                            packaging_factor=1.0,
                            recalculated_quantity=item_data.get('quantity', 1),
                            nomenclature_id=nomenclature.id
                        )
                        db.add(mapping)
                        print(f"Created mapping: {match['agb_article']} -> {match.get('code_1c', '')}")
        
        await db.commit()
        await db.refresh(request)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        matching_results = await perform_matching(request.id, db)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–∞—è–≤–∫—É —Å –ø–æ–∑–∏—Ü–∏—è–º–∏
        result = await db.execute(
            select(ContractorRequest)
            .options(selectinload(ContractorRequest.items))
            .where(ContractorRequest.id == request.id)
        )
        request_with_items = result.scalar_one()
        
        return {
            "request": request_with_items,
            "matching_results": matching_results
        }
        
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞: {str(e)}")


def parse_text_to_items(text: str) -> List[dict]:
    """–ü–∞—Ä—Å–∏—Ç —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–∑–∏—Ü–∏–∏ –∑–∞—è–≤–∫–∏ - –∏—â–µ—Ç —Å—Ç—Ä–æ–∫–∏ –¥–ª–∏–Ω–Ω–µ–µ 4 —Å–∏–º–≤–æ–ª–æ–≤"""
    items = []
    lines = [line.strip() for line in text.strip().split('\n') if line.strip()]
    
    print(f"Parsing text with {len(lines)} lines:")
    for idx, line in enumerate(lines):
        print(f"  {idx}: '{line}' (length: {len(line)})")
    
    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª–∏–Ω–Ω–µ–µ 4 —Å–∏–º–≤–æ–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ —Ç–æ–≤–∞—Ä–æ–≤
    for line in lines:
        if len(line) > 4:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            if (line.startswith('–ù–æ–≤–∞—è –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å') or 
                line.startswith('–î–ª—è') or 
                line.lower() in ['—à—Ç', '—à—Ç.', '—à—Ç—É–∫', '—à—Ç—É–∫.', 'pcs', 'pcs.', 'pieces', 'pieces.'] or
                re.match(r'^\d+$', line)):
                continue
            
            # –≠—Ç–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            item = {
                'agb_article': '',  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ AI –ø–æ–∏—Å–∫–æ–º
                'description': line,
                'quantity': 1,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                'unit': '—à—Ç'    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            }
            print(f"Found potential item: {item}")
            items.append(item)
    
    return items


@router.get("/our-database/")
async def get_our_database(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—à–µ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä"""
    try:
        result = await db.execute(select(MatchingNomenclature))
        nomenclatures = result.scalars().all()
        
        return [
            {
                "id": nom.id,
                "agb_article": nom.agb_article,
                "name": nom.name,
                "code_1c": nom.code_1c
            }
            for nom in nomenclatures
        ]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {str(e)}")


@router.get("/test-our-database/")
async def test_our_database(db: AsyncSession = Depends(get_db)):
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    try:
        result = await db.execute(select(MatchingNomenclature))
        nomenclatures = result.scalars().all()
        
        return {
            "count": len(nomenclatures),
            "data": [
                {
                    "id": nom.id,
                    "agb_article": nom.agb_article,
                    "name": nom.name,
                    "code_1c": nom.code_1c,
                    "bl_article": nom.bl_article,
                    "packaging": nom.packaging,
                    "unit": nom.unit,
                    "is_active": nom.is_active
                }
                for nom in nomenclatures  # –í—Å–µ –∑–∞–ø–∏—Å–∏
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {str(e)}")


@router.get("/found-items/")
async def get_found_items(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞–º–∏
        result = await db.execute(
            select(ArticleMapping)
            .options(selectinload(ArticleMapping.nomenclature))
            .options(selectinload(ArticleMapping.contractor_request_item))
        )
        mappings = result.scalars().all()
        
        found_items = []
        for mapping in mappings:
            item = {
                "id": mapping.id,
                "bl_article": mapping.bl_article,
                "search_article": mapping.contractor_request_item.contractor_article if mapping.contractor_request_item else None,
                "our_article": mapping.agb_article,
                "ut_number": mapping.nomenclature.code_1c if mapping.nomenclature else None,
                "found_data": mapping.nomenclature.name if mapping.nomenclature else None,
                "match_confidence": mapping.match_confidence,
                "packaging_factor": mapping.packaging_factor,
                "recalculated_quantity": mapping.recalculated_quantity
            }
            found_items.append(item)
        
        return found_items
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {str(e)}")


@router.get("/test-found-items-debug/")
async def test_found_items_debug(db: AsyncSession = Depends(get_db)):
    """–û—Ç–ª–∞–¥–æ—á–Ω—ã–π endpoint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        result_all = await db.execute(select(ArticleMapping))
        all_mappings = result_all.scalars().all()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        result_active = await db.execute(select(ArticleMapping).where(ArticleMapping.is_active == True))
        active_mappings = result_active.scalars().all()
        
        return {
            "total_count": len(all_mappings),
            "active_count": len(active_mappings),
            "inactive_count": len(all_mappings) - len(active_mappings),
            "message": "–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"
        }
    except Exception as e:
        return {"error": str(e)}


@router.get("/test-found-items/")
async def test_found_items(db: AsyncSession = Depends(get_db)):
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –±–µ–∑ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º SQLAlchemy ORM –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö, —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–µ
        result = await db.execute(select(ArticleMapping).where(ArticleMapping.is_active == True))
        mappings = result.scalars().all()
        
        found_items = []
        for mapping in mappings:
            item = {
                "id": mapping.id,
                "mapping_id": mapping.id,  # –î–æ–±–∞–≤–ª—è–µ–º mapping_id –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
                "bl_article": mapping.bl_article,
                "search_article": mapping.contractor_article,
                "our_article": mapping.agb_article,
                "ut_number": mapping.agb_description,
                "found_data": mapping.contractor_description,
                "match_confidence": 100.0,
                "packaging_factor": mapping.packaging_factor,
                "recalculated_quantity": 1
            }
            found_items.append(item)
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∑–∞–ø–∏—Å—å: {mapping.id} - {mapping.agb_article} -> {mapping.bl_article}")
        
        return {
            "count": len(mappings),
            "data": found_items
        }
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ test_found_items: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {str(e)}")


@router.put("/nomenclature/{nomenclature_id}/")
async def update_nomenclature(
    nomenclature_id: int,
    nomenclature_data: dict,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
        if current_user.role not in ['ved_passport', 'admin']:
            raise HTTPException(status_code=403, detail="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∞–≤ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã")
        
        # –ù–∞—Ö–æ–¥–∏–º –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—É
        result = await db.execute(
            select(MatchingNomenclature).where(MatchingNomenclature.id == nomenclature_id)
        )
        nomenclature = result.scalar_one_or_none()
        
        if not nomenclature:
            raise HTTPException(status_code=404, detail="–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è
        nomenclature.agb_article = nomenclature_data.get('agb_article', nomenclature.agb_article)
        nomenclature.name = nomenclature_data.get('name', nomenclature.name)
        nomenclature.code_1c = nomenclature_data.get('code_1c', nomenclature.code_1c)
        nomenclature.bl_article = nomenclature_data.get('bl_article', nomenclature.bl_article)
        nomenclature.packaging = nomenclature_data.get('packaging', nomenclature.packaging)
        nomenclature.unit = nomenclature_data.get('unit', nomenclature.unit)
        nomenclature.is_active = nomenclature_data.get('is_active', nomenclature.is_active)
        
        await db.commit()
        
        return {
            "id": nomenclature.id,
            "agb_article": nomenclature.agb_article,
            "name": nomenclature.name,
            "code_1c": nomenclature.code_1c,
            "bl_article": nomenclature.bl_article,
            "packaging": nomenclature.packaging,
            "unit": nomenclature.unit,
            "is_active": nomenclature.is_active
        }
        
    except HTTPException:
        raise
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã: {str(e)}")


@router.put("/mapping/{mapping_id}/")
async def update_mapping(
    mapping_id: int,
    mapping_data: dict,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∞—Ä—Ç–∏–∫—É–ª–æ–≤"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
        if current_user.role not in ['ved_passport', 'admin']:
            raise HTTPException(status_code=403, detail="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∞–≤ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π")
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        result = await db.execute(
            select(ArticleMapping).where(ArticleMapping.id == mapping_id)
        )
        mapping = result.scalar_one_or_none()
        
        if not mapping:
            raise HTTPException(status_code=404, detail="–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è
        mapping.bl_article = mapping_data.get('bl_article', mapping.bl_article)
        mapping.contractor_article = mapping_data.get('search_article', mapping.contractor_article)
        mapping.agb_article = mapping_data.get('our_article', mapping.agb_article)
        mapping.agb_description = mapping_data.get('ut_number', mapping.agb_description)
        mapping.contractor_description = mapping_data.get('found_data', mapping.contractor_description)
        mapping.match_confidence = mapping_data.get('match_confidence', mapping.match_confidence)
        mapping.packaging_factor = mapping_data.get('packaging_factor', mapping.packaging_factor)
        mapping.recalculated_quantity = mapping_data.get('recalculated_quantity', mapping.recalculated_quantity)
        
        await db.commit()
        
        return {
            "id": mapping.id,
            "bl_article": mapping.bl_article,
            "search_article": mapping.contractor_article,
            "our_article": mapping.agb_article,
            "ut_number": mapping.agb_description,
            "found_data": mapping.contractor_description,
            "match_confidence": mapping.match_confidence,
            "packaging_factor": mapping.packaging_factor,
            "recalculated_quantity": mapping.recalculated_quantity
        }
        
    except HTTPException:
        raise
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: {str(e)}")


async def perform_matching(request_id: int, db: AsyncSession) -> dict:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –¥–ª—è –∑–∞—è–≤–∫–∏"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞—è–≤–∫–∏
        result = await db.execute(
            select(ContractorRequestItem).where(ContractorRequestItem.request_id == request_id)
        )
        items = result.scalars().all()
        
        if not items:
            return {"message": "–ù–µ—Ç —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"}
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        existing_mappings_result = await db.execute(select(ArticleMapping))
        existing_mappings = existing_mappings_result.scalars().all()
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π
        existing_by_contractor_article = {
            mapping.contractor_article: mapping for mapping in existing_mappings
        }
        
        new_mappings = []
        matched_items = []
        
        for item in items:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —ç—Ç–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–∞
            if item.contractor_article in existing_by_contractor_article:
                existing_mapping = existing_by_contractor_article[item.contractor_article]
                matched_items.append({
                    "line_number": item.line_number,
                    "contractor_article": item.contractor_article,
                    "description": item.description,
                    "agb_article": existing_mapping.agb_article,
                    "bl_article": existing_mapping.bl_article,
                    "match_confidence": existing_mapping.match_confidence,
                    "packaging_factor": existing_mapping.packaging_factor,
                    "recalculated_quantity": item.quantity * existing_mapping.packaging_factor,
                    "source": "existing"
                })
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ AI
                ai_result = await smart_search_with_ai(item.description, db)
                
                if ai_result.get("matches"):
                    # –ë–µ—Ä–µ–º –ª—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
                    best_match = ai_result["matches"][0]
                    
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
                    new_mapping = ArticleMapping(
                        contractor_article=item.contractor_article,
                        contractor_description=item.description,
                        agb_article=best_match.get("agb_article", ""),
                        agb_description=best_match.get("name", ""),
                        bl_article=best_match.get("bl_article", ""),
                        match_confidence=int(best_match.get("confidence", 0)),
                        packaging_factor=int(best_match.get("packaging", 1)),
                        recalculated_quantity=item.quantity * int(best_match.get("packaging", 1))
                    )
                    db.add(new_mapping)
                    new_mappings.append(new_mapping)
                    
                    matched_items.append({
                        "line_number": item.line_number,
                        "contractor_article": item.contractor_article,
                        "description": item.description,
                        "agb_article": best_match.get("agb_article", ""),
                        "bl_article": best_match.get("bl_article", ""),
                        "match_confidence": int(best_match.get("confidence", 0)),
                        "packaging_factor": int(best_match.get("packaging", 1)),
                        "recalculated_quantity": item.quantity * int(best_match.get("packaging", 1)),
                        "source": "new",
                        "search_type": ai_result.get("search_type", "general")
                    })
                else:
                    # –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
                    matched_items.append({
                        "line_number": item.line_number,
                        "contractor_article": item.contractor_article or '',
                        "description": item.description or '',
                        "agb_article": '',
                        "bl_article": '',
                        "match_confidence": 0,
                        "packaging_factor": 1.0,
                        "recalculated_quantity": item.quantity,
                        "source": "not_found"
                    })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        if new_mappings:
            await db.commit()
        
        return {
            "total_items": len(items),
            "matched_items": len([item for item in matched_items if item["agb_article"]]),
            "new_mappings_count": len(new_mappings),
            "existing_mappings_count": len([item for item in matched_items if item["source"] == "existing"]),
            "not_found_count": len([item for item in matched_items if item["source"] == "not_found"]),
            "results": matched_items
        }
        
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {str(e)}")


@router.post("/requests/{request_id}/match/")
async def match_request_items(
    request_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –¥–ª—è –∑–∞—è–≤–∫–∏"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
        if current_user.role not in ['ved_passport', 'admin']:
            raise HTTPException(status_code=403, detail="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∞–≤ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞—è–≤–∫–∞ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        result = await db.execute(
            select(ContractorRequest).where(ContractorRequest.id == request_id)
        )
        request = result.scalar_one_or_none()
        
        if not request or request.created_by != current_user.id:
            raise HTTPException(status_code=404, detail="–ó–∞—è–≤–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        matching_results = await perform_matching(request_id, db)
        
        return matching_results
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {str(e)}")


@router.post("/test-upload-excel/")
async def test_upload_excel(
    file: UploadFile = File(...),
    contractor_name: str = "–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç",
    db: AsyncSession = Depends(get_db)
):
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ Excel –±–µ–∑ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    try:
        # –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª
        content = await file.read()
        df = pd.read_excel(io.BytesIO(content))
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–º–µ—Ä –∑–∞—è–≤–∫–∏
        request_number = f"TEST_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞—è–≤–∫—É
        new_request = ContractorRequest(
            request_number=request_number,
            contractor_name=contractor_name,
            request_date=datetime.now(),
            total_items=5,  # –¢–µ—Å—Ç–æ–≤–∞—è –∑–∞—è–≤–∫–∞ –∏–∑ 5 –ø–æ–∑–∏—Ü–∏–π
            created_by=1  # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        )
        
        db.add(new_request)
        await db.flush()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞—è–≤–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–º–µ—Ä–∞
        test_items = [
            {"agb_article": "1299650", "description": "–®–ø–∏–Ω–¥–µ–ª—å –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ –∫–µ—Ä–Ω–æ–ø—Ä–∏–µ–º–Ω–∏–∫–∞ H/HU, 25231, SDT", "quantity": 5, "unit": "—à—Ç"},
            {"agb_article": "1298240", "description": "–í—Ç—É–ª–∫–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è –∂–∏–¥–∫–æ—Å—Ç–∏ 306131, SDT", "quantity": 12, "unit": "—à—Ç"},
            {"agb_article": "1298244", "description": "–ü—Ä—É–∂–∏–Ω–∞ –º—è–≥–∫–∞—è N/H/P, —É–¥–µ—Ä–∂–∞–Ω–∏—è –∂–∏–¥–∫–æ—Å—Ç–∏, 104966, SDT", "quantity": 10, "unit": "—à—Ç"},
            {"agb_article": "1299679", "description": "–©–µ–∫–∞ –≤–µ—Ä—Ö–Ω—è—è –¥–ª—è –∫–ª—é—á–∞ —Ä–∞–∑–≤–æ–¥–Ω–æ–≥–æ 24\", 14947, SDT", "quantity": 8, "unit": "—à—Ç"},
            {"agb_article": "1299680", "description": "–©–µ–∫–∞ –≤–µ—Ä—Ö–Ω—è—è –¥–ª—è –∫–ª—é—á–∞ —Ä–∞–∑–≤–æ–¥–Ω–æ–≥–æ 36\", 14950, SDT", "quantity": 8, "unit": "—à—Ç"}
        ]
        
        items = []
        for index, item_data in enumerate(test_items):
            line_number = index + 1
            new_item = ContractorRequestItem(
                request_id=new_request.id,
                line_number=line_number,
                contractor_article=item_data["agb_article"],
                description=item_data["description"],
                unit=item_data["unit"],
                quantity=item_data["quantity"],
                category="–î–ª—è –±—É—Ä–µ–Ω–∏—è"
            )
            db.add(new_item)
            items.append(new_item)
        
        await db.commit()
        await db.refresh(new_request)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        matching_results = await perform_matching(new_request.id, db)
        
        return {
            "request": new_request,
            "matching_results": matching_results
        }
        
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")


@router.post("/smart-search/")
async def smart_search_endpoint(
    request_data: dict,
    db: AsyncSession = Depends(get_db)
):
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ AI"""
    try:
        search_text = request_data.get("search_text", "")
        if not search_text:
            raise HTTPException(status_code=400, detail="–ù–µ —É–∫–∞–∑–∞–Ω —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞")
        
        print(f"–í—ã–ø–æ–ª–Ω—è–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è: {search_text}")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫
        result = await smart_search_with_ai(search_text, db)
        
        return result
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"–û—à–∏–±–∫–∞ –≤ smart_search_endpoint: {str(e)}")
        print(f"Traceback: {error_details}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {str(e)}")


@router.post("/smart-upload/")
async def smart_upload_file(
    file: UploadFile = File(...),
    contractor_name: str = "–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç",
    db: AsyncSession = Depends(get_db)
):
    """–£–º–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ª—é–±–æ–≥–æ —Ñ–∞–π–ª–∞ —Å AI –ø–æ–∏—Å–∫–æ–º"""
    try:
        print(f"–ù–∞—á–∏–Ω–∞–µ–º —É–º–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞: {file.filename}")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        content = await file.read()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏ –ø–∞—Ä—Å–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        file_extension = file.filename.split(".")[-1].lower() if file.filename else ""
        
        search_items = []
        
        if file_extension in ["xlsx", "xls"]:
            # Excel —Ñ–∞–π–ª
            df = pd.read_excel(io.BytesIO(content))
            print(f"Excel —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç {len(df)} —Å—Ç—Ä–æ–∫")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Excel
            for index, row in df.iterrows():
                for col in df.columns:
                    cell_value = str(row[col]).strip()
                    if len(cell_value) > 3 and cell_value != "nan":
                        search_items.append({
                            "text": cell_value,
                            "row": index + 1,
                            "column": col
                        })
        
        elif file_extension in ["txt", "csv"]:
            # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            text_content = content.decode("utf-8", errors="ignore")
            lines = [line.strip() for line in text_content.split("\n") if line.strip()]
            
            for index, line in enumerate(lines):
                if len(line) > 3:
                    search_items.append({
                        "text": line,
                        "row": index + 1,
                        "column": "text"
                    })
        
        else:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç
            try:
                text_content = content.decode("utf-8", errors="ignore")
                lines = [line.strip() for line in text_content.split("\n") if line.strip()]
                
                for index, line in enumerate(lines):
                    if len(line) > 3:
                        search_items.append({
                            "text": line,
                            "row": index + 1,
                            "column": "text"
                        })
            except:
                raise HTTPException(status_code=400, detail="–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞")
        
        if not search_items:
            raise HTTPException(status_code=400, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞")
        
        print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(search_items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞—è–≤–∫—É
        request_number = f"SMART_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        new_request = ContractorRequest(
            request_number=request_number,
            contractor_name=contractor_name,
            request_date=datetime.now(),
            total_items=len(search_items),
            created_by=1  # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        )
        
        db.add(new_request)
        await db.flush()
        
        # –°–æ–∑–¥–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞—è–≤–∫–∏
        items = []
        for search_item in search_items:
            # –°–æ–∑–¥–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç –∑–∞—è–≤–∫–∏
            item = ContractorRequestItem(
                request_id=new_request.id,
                line_number=search_item["row"],
                contractor_article=search_item["text"][:50],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                description=search_item["text"],
                quantity=1,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                unit="—à—Ç",
                category="AI –ø–æ–∏—Å–∫"
            )
            db.add(item)
            items.append(item)
        
        await db.commit()
        await db.refresh(new_request)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        matching_results = await perform_matching(new_request.id, db)
        
        return {
            "request": new_request,
            "matching_results": matching_results,
            "search_items_count": len(search_items),
            "file_type": file_extension
        }
        
    except Exception as e:
        await db.rollback()
        import traceback
        error_details = traceback.format_exc()
        print(f"–û—à–∏–±–∫–∞ –≤ smart_upload_file: {str(e)}")
        print(f"Traceback: {error_details}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–º–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")


@router.post("/step-upload/")
async def step_upload_file(
    file: UploadFile = File(...),
    contractor_name: str = "–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç",
    db: AsyncSession = Depends(get_db)
):
    """–ü–æ—à–∞–≥–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –≤–∏–¥–∏–º—ã–º–∏ —ç—Ç–∞–ø–∞–º–∏"""
    try:
        print(f"üöÄ –≠—Ç–∞–ø 1: –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞: {file.filename}")
        
        # –≠—Ç–∞–ø 1: –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        content = await file.read()
        print(f"‚úÖ –≠—Ç–∞–ø 1 –∑–∞–≤–µ—Ä—à–µ–Ω: –§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω ({len(content)} –±–∞–π—Ç)")
        
        # –≠—Ç–∞–ø 2: –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏ –ø–∞—Ä—Å–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        file_extension = file.filename.split(".")[-1].lower() if file.filename else ""
        print(f"üîç –≠—Ç–∞–ø 2: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª —Ç–∏–ø–∞ {file_extension}")
        
        search_items = []
        
        if file_extension in ["xlsx", "xls"]:
            # Excel —Ñ–∞–π–ª
            df = pd.read_excel(io.BytesIO(content))
            print(f"üìä –≠—Ç–∞–ø 2: Excel —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç {len(df)} —Å—Ç—Ä–æ–∫")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –µ–¥–∏–Ω–æ–µ —Ü–µ–ª–æ–µ
            for index, row in df.iterrows():
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —è—á–µ–π–∫–∏ —Å—Ç—Ä–æ–∫–∏ –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
                row_text = " ".join([str(cell).strip() for cell in row.values if str(cell).strip() != "nan" and len(str(cell).strip()) > 0])
                
                if len(row_text) > 3:
                    search_items.append({
                        "text": row_text,
                        "row": index + 1,
                        "column": "row"
                    })
        
        elif file_extension in ["txt", "csv"]:
            # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            text_content = content.decode("utf-8", errors="ignore")
            lines = [line.strip() for line in text_content.split("\n") if line.strip()]
            
            for index, line in enumerate(lines):
                if len(line) > 3:
                    search_items.append({
                        "text": line,
                        "row": index + 1,
                        "column": "text"
                    })
        
        else:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç
            try:
                text_content = content.decode("utf-8", errors="ignore")
                lines = [line.strip() for line in text_content.split("\n") if line.strip()]
                
                for index, line in enumerate(lines):
                    if len(line) > 3:
                        search_items.append({
                            "text": line,
                            "row": index + 1,
                            "column": "text"
                        })
            except:
                raise HTTPException(status_code=400, detail="–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞")
        
        if not search_items:
            raise HTTPException(status_code=400, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞")
        
        print(f"‚úÖ –≠—Ç–∞–ø 2 –∑–∞–≤–µ—Ä—à–µ–Ω: –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(search_items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞")
        
        # –≠—Ç–∞–ø 3: –°–æ–∑–¥–∞–µ–º –∑–∞—è–≤–∫—É –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        print(f"üíæ –≠—Ç–∞–ø 3: –°–æ–∑–¥–∞–µ–º –∑–∞—è–≤–∫—É –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–º–µ—Ä –∑–∞—è–≤–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ {–Ω–∞–∑–≤–∞–Ω–∏–µ_–∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞}_{–ø–æ—Ä—è–¥–∫–æ–≤—ã–π_–Ω–æ–º–µ—Ä}_{–¥–∞—Ç–∞}
        contractor_name_latin = transliterate_to_latin(contractor_name)
        print(f"üî§ –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è: '{contractor_name}' -> '{contractor_name_latin}'")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞—è–≤–æ–∫ –¥–ª—è —ç—Ç–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ —Å–µ–≥–æ–¥–Ω—è
        today = datetime.now().date()
        count_result = await db.execute(
            select(func.count(ContractorRequest.id)).where(
                ContractorRequest.contractor_name == contractor_name,
                func.date(ContractorRequest.request_date) == today
            )
        )
        request_count = count_result.scalar() + 1
        
        request_number = f"{contractor_name_latin}_{request_count:03d}_{datetime.now().strftime('%Y%m%d')}"
        new_request = ContractorRequest(
            request_number=request_number,
            contractor_name=contractor_name,
            request_date=datetime.now(),
            total_items=0,  # –ë—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–æ –ø–æ—Å–ª–µ AI –æ–±—Ä–∞–±–æ—Ç–∫–∏
            created_by=1  # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        )
        
        db.add(new_request)
        await db.flush()
        
        # –°–æ–∑–¥–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞—è–≤–∫–∏ —Å AI –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∞—Ä—Ç–∏–∫—É–ª–æ–≤
        items = []
        total_articles_found = 0
        
        print(f"üîç –≠—Ç–∞–ø 3: –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª—ã –∏–∑ {len(search_items)} —Å—Ç—Ä–æ–∫ —á–µ—Ä–µ–∑ AI")
        
        for i, search_item in enumerate(search_items):
            print(f"üìù –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É {i+1}/{len(search_items)}: {search_item['text'][:50]}...")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏ —á–µ—Ä–µ–∑ AI
            articles = await extract_articles_from_text(search_item["text"], db)
            
            if articles:
                print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(articles)} –∞—Ä—Ç–∏–∫—É–ª–æ–≤")
                total_articles_found += len(articles)
                
                # –°–æ–∑–¥–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç –∑–∞—è–≤–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–∞
                for article_data in articles:
                    item = ContractorRequestItem(
                        request_id=new_request.id,
                        line_number=search_item["row"],
                        contractor_article=article_data.get("article", "")[:50],
                        description=article_data.get("description", search_item["text"]),
                        quantity=article_data.get("quantity", 1),
                        unit=article_data.get("unit", "—à—Ç"),
                        category="AI –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ"
                    )
                    db.add(item)
                    items.append(item)
            else:
                print(f"  ‚ùå –ê—Ä—Ç–∏–∫—É–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                # –°–æ–∑–¥–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç –∑–∞—è–≤–∫–∏ —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
                item = ContractorRequestItem(
                    request_id=new_request.id,
                    line_number=search_item["row"],
                    contractor_article="",  # –ê—Ä—Ç–∏–∫—É–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
                    description=search_item["text"],
                    quantity=1,
                    unit="—à—Ç",
                    category="–ë–µ–∑ –∞—Ä—Ç–∏–∫—É–ª–∞"
                )
                db.add(item)
                items.append(item)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        new_request.total_items = len(items)
        
        await db.commit()
        print(f"‚úÖ –≠—Ç–∞–ø 3 –∑–∞–≤–µ—Ä—à–µ–Ω: –ó–∞—è–≤–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ —Å ID {new_request.id}")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {len(search_items)} —Å—Ç—Ä–æ–∫ -> {total_articles_found} –∞—Ä—Ç–∏–∫—É–ª–æ–≤ -> {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∑–∞—è–≤–∫–∏")
        
        # –≠—Ç–∞–ø 4: –ó–∞–ø—É—Å–∫–∞–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–µ
        print(f"üîÑ –≠—Ç–∞–ø 4: –ó–∞–ø—É—Å–∫–∞–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–µ")
        import asyncio
        asyncio.create_task(perform_background_matching(new_request.id))
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        return {
            "success": True,
            "request_id": new_request.id,
            "request_number": request_number,
            "contractor_name": contractor_name,
            "rows_processed": len(search_items),
            "articles_found": total_articles_found,
            "total_items": len(items),
            "file_type": file_extension,
            "message": f"–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(search_items)} —Å—Ç—Ä–æ–∫, –Ω–∞–π–¥–µ–Ω–æ {total_articles_found} –∞—Ä—Ç–∏–∫—É–ª–æ–≤. –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ —Ñ–æ–Ω–µ.",
            "status": "uploaded"
        }
        
    except Exception as e:
        await db.rollback()
        import traceback
        error_details = traceback.format_exc()
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ step_upload_file: {str(e)}")
        print(f"Traceback: {error_details}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")


async def perform_background_matching(request_id: int):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–µ"""
    from database import get_db
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏
    async for db in get_db():
        try:
            print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º —Ñ–æ–Ω–æ–≤–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –∑–∞—è–≤–∫–∏ {request_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞—è–≤–∫–∏
            result = await db.execute(
                select(ContractorRequestItem).where(ContractorRequestItem.request_id == request_id)
            )
            items = result.scalars().all()
            
            if not items:
                print(f"‚ùå –≠–ª–µ–º–µ–Ω—Ç—ã –∑–∞—è–≤–∫–∏ {request_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                break
            
            print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
            matched_count = 0
            for i, item in enumerate(items):
                print(f"üîç –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º {i+1}/{len(items)}: {item.description[:50]}...")
                
                try:
                    # –í—ã–ø–æ–ª–Ω—è–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫
                    ai_result = await smart_search_with_ai(item.description, db)
                    
                    if ai_result.get("matches"):
                        # –ë–µ—Ä–µ–º –ª—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
                        best_match = ai_result["matches"][0]
                        
                        # –°–æ–∑–¥–∞–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
                        mapping = ArticleMapping(
                            contractor_article=item.contractor_article,
                            contractor_description=item.description,
                            agb_article=best_match.get("agb_article", ""),
                            agb_description=best_match.get("name", ""),
                            bl_article=best_match.get("bl_article", ""),
                            match_confidence=int(best_match.get("confidence", 0)),
                            packaging_factor=int(best_match.get("packaging", 1)),
                            recalculated_quantity=item.quantity * int(best_match.get("packaging", 1))
                        )
                        db.add(mapping)
                        matched_count += 1
                        
                        print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {best_match.get('agb_article', '')} | {best_match.get('name', '')} | {best_match.get('confidence', 0)}%")
                    else:
                        print(f"  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π")
                        
                except Exception as e:
                    print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {str(e)}")
                    continue
            
            await db.commit()
            print(f"üéâ –§–æ–Ω–æ–≤–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ù–∞–π–¥–µ–Ω–æ {matched_count} —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π.")
            break  # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ async for
            
        except Exception as e:
            await db.rollback()
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {str(e)}")
            break  # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ async for


@router.post("/test-upload-text/")
async def test_upload_text_request(
    request_data: TextUploadRequest,
    db: AsyncSession = Depends(get_db)
):
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    try:
        # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π
        items = parse_text_to_items(request_data.text)
        
        if not items:
            raise HTTPException(status_code=400, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞—è–≤–∫—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –Ω–æ–º–µ—Ä–æ–º
        contractor_name = request_data.contractor_name
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–º–µ—Ä –∑–∞—è–≤–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ {–Ω–∞–∑–≤–∞–Ω–∏–µ_–∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞}_{–ø–æ—Ä—è–¥–∫–æ–≤—ã–π_–Ω–æ–º–µ—Ä}_{–¥–∞—Ç–∞}
        contractor_name_latin = transliterate_to_latin(contractor_name)
        print(f"üî§ –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è: '{contractor_name}' -> '{contractor_name_latin}'")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞—è–≤–æ–∫ –¥–ª—è —ç—Ç–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ —Å–µ–≥–æ–¥–Ω—è
        today = datetime.now().date()
        count_result = await db.execute(
            select(func.count(ContractorRequest.id)).where(
                ContractorRequest.contractor_name == contractor_name,
                func.date(ContractorRequest.request_date) == today
            )
        )
        request_count = count_result.scalar() + 1
        
        request_number = f"{contractor_name_latin}_{request_count:03d}_{datetime.now().strftime('%Y%m%d')}"
        
        request = ContractorRequest(
            request_number=request_number,
            contractor_name=contractor_name,
            request_date=datetime.now(),
            total_items=len(items),
            status='new',
            created_by=1  # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        )
        
        db.add(request)
        await db.flush()  # –ü–æ–ª—É—á–∞–µ–º ID –∑–∞—è–≤–∫–∏
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –∑–∞—è–≤–∫–∏
        for i, item_data in enumerate(items):
            item = ContractorRequestItem(
                request_id=request.id,
                line_number=i + 1,  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏
                contractor_article=item_data.get('agb_article', ''),
                description=item_data.get('description', ''),
                quantity=item_data.get('quantity', 1),
                unit=item_data.get('unit', '—à—Ç'),
                category="–¢–µ–∫—Å—Ç–æ–≤—ã–π –≤–≤–æ–¥"
            )
            db.add(item)
        
        await db.commit()
        
        return {
            "success": True,
            "request": {
                "id": request.id,
                "request_number": request_number,
                "contractor_name": contractor_name,
                "total_items": len(items),
                "status": "new"
            },
            "message": f"–¢–µ–∫—Å—Ç–æ–≤–∞—è –∑–∞—è–≤–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(items)} –ø–æ–∑–∏—Ü–∏–π."
        }
        
    except Exception as e:
        await db.rollback()
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–≤–æ–¥–µ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞—è–≤–∫–∏: {str(e)}")

@router.post("/test-match/{request_id}")
async def test_match_request(
    request_id: int,
    db: AsyncSession = Depends(get_db)
):
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –±–µ–∑ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    try:
        print(f"üîÑ –¢–µ—Å—Ç–æ–≤–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –∑–∞—è–≤–∫–∏ {request_id}")
        
        # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞—è–≤–∫–∏
        result = await db.execute(
            select(ContractorRequestItem).where(ContractorRequestItem.request_id == request_id)
        )
        items = result.scalars().all()
        
        if not items:
            raise HTTPException(status_code=404, detail="–≠–ª–µ–º–µ–Ω—Ç—ã –∑–∞—è–≤–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        matched_count = 0
        unmatched_count = 0
        
        for i, item in enumerate(items):
            print(f"üîç –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º {i+1}/{len(items)}: {item.description[:50]}...")
            
            try:
                # –í—ã–ø–æ–ª–Ω—è–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫
                ai_result = await smart_search_with_ai(item.description, db)
                
                if ai_result.get("matches"):
                    # –ë–µ—Ä–µ–º –ª—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
                    best_match = ai_result["matches"][0]
                    
                    # –°–æ–∑–¥–∞–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
                    mapping = ArticleMapping(
                        contractor_article=item.contractor_article,
                        contractor_description=item.description,
                        agb_article=best_match.get("agb_article", ""),
                        agb_description=best_match.get("name", ""),
                        bl_article=best_match.get("bl_article", ""),
                        match_confidence=int(best_match.get("confidence", 0)),
                        packaging_factor=int(best_match.get("packaging", 1)),
                        recalculated_quantity=item.quantity * int(best_match.get("packaging", 1))
                    )
                    db.add(mapping)
                    matched_count += 1
                    
                    print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {best_match.get('agb_article', '')} | {best_match.get('name', '')} | {best_match.get('confidence', 0)}%")
                else:
                    unmatched_count += 1
                    print(f"  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π")
                    
            except Exception as e:
                print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {str(e)}")
                unmatched_count += 1
                continue
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        await db.commit()
        
        return {
            "total_items": len(items),
            "matched_items": matched_count,
            "unmatched_items": unmatched_count,
            "message": f"–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ù–∞–π–¥–µ–Ω–æ {matched_count} –∏–∑ {len(items)} –ø–æ–∑–∏—Ü–∏–π."
        }
        
    except Exception as e:
        await db.rollback()
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {str(e)}")


@router.get("/status/{request_id}")
async def get_request_status(
    request_id: int,
    db: AsyncSession = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞—è–≤–∫–∏"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞—è–≤–∫—É
        result = await db.execute(
            select(ContractorRequest).where(ContractorRequest.id == request_id)
        )
        request = result.scalar_one_or_none()
        
        if not request:
            raise HTTPException(status_code=404, detail="–ó–∞—è–≤–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π
        mapping_result = await db.execute(
            select(func.count(ArticleMapping.id))
        )
        total_mappings = mapping_result.scalar()
        
        # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞—è–≤–∫–∏
        items_result = await db.execute(
            select(ContractorRequestItem).where(ContractorRequestItem.request_id == request_id)
        )
        items = items_result.scalars().all()
        
        return {
            "request_id": request_id,
            "request_number": request.request_number,
            "status": "completed" if len(items) > 0 else "processing",
            "total_items": len(items),
            "total_mappings": total_mappings,
            "message": "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞" if len(items) > 0 else "–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞: {str(e)}")


@router.post("/requests/{request_id}/smart-match/")
async def smart_match_request(
    request_id: int,
    db: AsyncSession = Depends(get_db)
):
    """–£–º–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏ —á–µ—Ä–µ–∑ AI"""
    try:
        print(f"–ù–∞—á–∏–Ω–∞–µ–º —É–º–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏ {request_id}")
        
        # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞—è–≤–∫–∏
        result = await db.execute(
            select(ContractorRequestItem).where(ContractorRequestItem.request_id == request_id)
        )
        items = result.scalars().all()
        
        if not items:
            raise HTTPException(status_code=404, detail="–≠–ª–µ–º–µ–Ω—Ç—ã –∑–∞—è–≤–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        matched_count = 0
        for item in items:
            print(f"–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º: {item.description}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫
            ai_result = await smart_search_with_ai(item.description, db)
            
            if ai_result.get("matches"):
                # –ë–µ—Ä–µ–º –ª—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
                best_match = ai_result["matches"][0]
                
                # –°–æ–∑–¥–∞–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
                mapping = ArticleMapping(
                    contractor_article=item.contractor_article,
                    contractor_description=item.description,
                    agb_article=best_match.get("agb_article", ""),
                    agb_description=best_match.get("name", ""),
                    bl_article=best_match.get("bl_article", ""),
                    match_confidence=int(best_match.get("confidence", 0)),
                    packaging_factor=int(best_match.get("packaging", 1)),
                    recalculated_quantity=item.quantity * int(best_match.get("packaging", 1))
                )
                db.add(mapping)
                matched_count += 1
                
                print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {best_match.get('agb_article', '')} | {best_match.get('name', '')} | {best_match.get('confidence', 0)}%")
            else:
                print(f"  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π")
        
        await db.commit()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        matching_results = await perform_matching(request_id, db)
        
        return {
            "request_id": request_id,
            "matching_results": matching_results,
            "matched_count": matched_count,
            "message": f"–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ù–∞–π–¥–µ–Ω–æ {matched_count} –Ω–æ–≤—ã—Ö —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π."
        }
        
    except Exception as e:
        await db.rollback()
        import traceback
        error_details = traceback.format_exc()
        print(f"–û—à–∏–±–∫–∞ –≤ smart_match_request: {str(e)}")
        print(f"Traceback: {error_details}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {str(e)}")


@router.get("/test-requests/")
async def test_get_requests(db: AsyncSession = Depends(get_db)):
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞—è–≤–æ–∫ –±–µ–∑ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    try:
        result = await db.execute(
            select(ContractorRequest)
            .options(selectinload(ContractorRequest.items))
            .order_by(ContractorRequest.created_at.desc())
            .limit(10)
        )
        requests = result.scalars().all()
        
        return {
            "count": len(requests),
            "data": requests
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∑–∞—è–≤–æ–∫: {str(e)}")


# –ò–ò –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
UPLOAD_DIR = Path("uploads/ai_processing")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

ALLOWED_EXTENSIONS = {
    'pdf': ['.pdf'],
    'excel': ['.xlsx', '.xls', '.csv', '.ods'],
    'word': ['.doc', '.docx', '.odt', '.rtf'],
    'powerpoint': ['.ppt', '.pptx', '.odp'],
    'text': ['.txt', '.rtf'],
    'images': ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp', '.svg']
}

def get_file_extension(filename: str) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
    return Path(filename).suffix.lower()

def is_allowed_file(filename: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Ä–∞–∑—Ä–µ—à–µ–Ω –ª–∏ —Ç–∏–ø —Ñ–∞–π–ª–∞"""
    ext = get_file_extension(filename)
    return any(ext in extensions for extensions in ALLOWED_EXTENSIONS.values())

async def extract_text_from_pdf(file_path: str) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞"""
    try:
        import PyPDF2
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF: {str(e)}")

async def extract_text_from_excel(file_path: str) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ Excel —Ñ–∞–π–ª–∞"""
    try:
        df = pd.read_excel(file_path)
        text = ""
        for index, row in df.iterrows():
            text += " ".join([str(cell) for cell in row if pd.notna(cell)]) + "\n"
        return text.strip()
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ Excel: {str(e)}")

async def extract_text_from_image(file_path: str) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é OCR"""
    try:
        from PIL import Image
        import pytesseract
        
        image = Image.open(file_path)
        text = pytesseract.image_to_string(image, lang='rus+eng')
        return text.strip()
    except Exception as e:
        # Fallback: –ø–æ–ø—Ä–æ–±—É–µ–º –±–µ–∑ —è–∑—ã–∫–æ–≤
        try:
            from PIL import Image
            import pytesseract
            image = Image.open(file_path)
            text = pytesseract.image_to_string(image)
            return text.strip()
        except Exception as fallback_error:
            raise Exception(f"–û—à–∏–±–∫–∞ OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}, Fallback: {str(fallback_error)}")
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")

async def extract_text_from_word(file_path: str) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ Word –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        from docx import Document
        doc = Document(file_path)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text.strip()
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ Word: {str(e)}")

async def extract_text_from_powerpoint(file_path: str) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PowerPoint –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏"""
    try:
        from pptx import Presentation
        prs = Presentation(file_path)
        text = ""
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    text += shape.text + "\n"
        return text.strip()
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ PowerPoint: {str(e)}")

async def extract_text_from_text_file(file_path: str) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞"""
    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        encodings = ['utf-8', 'cp1251', 'latin-1', 'iso-8859-1']
        text = ""
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as file:
                    text = file.read()
                break
            except UnicodeDecodeError:
                continue
        
        if not text:
            # –ï—Å–ª–∏ –≤—Å–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, —á–∏—Ç–∞–µ–º –∫–∞–∫ –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–π–ª
            with open(file_path, 'rb') as file:
                content = file.read()
                text = content.decode('utf-8', errors='ignore')
        
        return text.strip()
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞: {str(e)}")

async def extract_text_from_file(file_path: str, filename: str) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –µ–≥–æ —Ç–∏–ø–∞"""
    ext = get_file_extension(filename)
    
    if ext in ALLOWED_EXTENSIONS['pdf']:
        return await extract_text_from_pdf(file_path)
    elif ext in ALLOWED_EXTENSIONS['excel']:
        return await extract_text_from_excel(file_path)
    elif ext in ALLOWED_EXTENSIONS['word']:
        return await extract_text_from_word(file_path)
    elif ext in ALLOWED_EXTENSIONS['powerpoint']:
        return await extract_text_from_powerpoint(file_path)
    elif ext in ALLOWED_EXTENSIONS['text']:
        return await extract_text_from_text_file(file_path)
    elif ext in ALLOWED_EXTENSIONS['images']:
        return await extract_text_from_image(file_path)
    else:
        raise Exception(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {ext}")

async def get_ai_response(text: str, api_key: str, provider: str) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò"""
    try:
        if provider == 'openai':
            import openai
            openai.api_key = api_key
            response = await openai.ChatCompletion.acreate(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": """–¢–´ - –ò–ò-–°–ü–ï–¶–ò–ê–õ–ò–°–¢ –ü–û –ò–ó–í–õ–ï–ß–ï–ù–ò–Æ –ò –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Æ –ê–†–¢–ò–ö–£–õ–û–í –ö–û–ú–ü–ê–ù–ò–ò –ê–ì–ë.

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –¢–í–û–Ø –û–°–ù–û–í–ù–ê–Ø –ó–ê–î–ê–ß–ê: –ò–∑–≤–ª–µ–∫–∞—Ç—å –∞—Ä—Ç–∏–∫—É–ª—ã –∏ —Ç–æ–≤–∞—Ä—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤/—Ç–µ–∫—Å—Ç–∞
2. –ï–°–õ–ò —ç—Ç–æ –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–∏—Å–∫ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–µ—Ä–Ω–∏ JSON —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
3. –ï–°–õ–ò —ç—Ç–æ –æ–±—ã—á–Ω—ã–π —á–∞—Ç - –æ—Ç–≤–µ—á–∞–π –∫–∞–∫ –ø–æ–º–æ—â–Ω–∏–∫

–ü–†–ò–ó–ù–ê–ö–ò –ê–†–¢–ò–ö–£–õ–û–í –ö–û–ú–ü–ê–ù–ò–ò –ê–ì–ë:
- –§–æ—Ä–º–∞—Ç: –ê–ì–ë-XXXXXX, –ê–ì–ëXXXXXX (6-8 —Ü–∏—Ñ—Ä)
- BL-XXXXXX, BLXXXXXX (–∞—Ä—Ç–∏–∫—É–ª—ã "–±–æ—Ä—Ç–ª–∞–Ω–≥–µ—Ä")
- –û–•–ö–£-XXXXXX, –û–•–ö–£XXXXXX (–∞—Ä—Ç–∏–∫—É–ª—ã)
- –ö–æ–¥—ã 1–°: —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–¥—ã (–£–¢-–∫–æ–¥—ã)
- –°–æ—á–µ—Ç–∞–Ω–∏—è: —Ü–∏—Ñ—Ä—ã + –±—É–∫–≤—ã (1234BL, BL1234)

–ò–ó–í–õ–ï–ö–ê–ô –ò–ù–§–û–†–ú–ê–¶–ò–Æ:
- –ê—Ä—Ç–∏–∫—É–ª—ã –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤ (–ª—é–±—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã)
- –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ (–Ω–∞ —Ä—É—Å—Å–∫–æ–º/–∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
- –û–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê –î–õ–Ø –ê–†–¢–ò–ö–£–õ–û–í:
[
    {
        "contractor_article": "–∞—Ä—Ç–∏–∫—É–ª –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)",
        "description": "–ø–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞",
        "quantity": —á–∏—Å–ª–æ,
        "unit": "—à—Ç/–∫–≥/–ª/–º¬≤/–º¬≥",
        "agb_article": "–∞—Ä—Ç–∏–∫—É–ª –ê–ì–ë (–µ—Å–ª–∏ –ø–æ—Ö–æ–∂)",
        "bl_article": "BL –∞—Ä—Ç–∏–∫—É–ª (–µ—Å–ª–∏ –ø–æ—Ö–æ–∂)",
        "match_confidence": 85,
        "match_type": "exact/partial/by_name"
    }
]

–ü–†–ê–í–ò–õ–ê –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø:
- –ò–©–ò –í–°–ï –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã –≤ —Ç–µ–∫—Å—Ç–µ
- –ù–ï –ü–†–û–ü–£–°–ö–ê–ô —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ - –æ–Ω–∏ —Ç–æ–∂–µ –≤–∞–∂–Ω—ã
- –ï–°–õ–ò –∞—Ä—Ç–∏–∫—É–ª —Å–æ–¥–µ—Ä–∂–∏—Ç "BL", "–±–æ—Ä—Ç" - —ç—Ç–æ BL –∞—Ä—Ç–∏–∫—É–ª
- –ï–°–õ–ò –∞—Ä—Ç–∏–∫—É–ª —Å–æ–¥–µ—Ä–∂–∏—Ç "–ê–ì–ë" - —ç—Ç–æ –ê–ì–ë –∞—Ä—Ç–∏–∫—É–ª
- –ö–û–õ–ò–ß–ï–°–¢–í–û: –∏—â–∏ —á–∏—Å–ª–∞ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è
- –ï–°–õ–ò –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–µ—Ç - —Å—Ç–∞–≤—å 1

–ü–†–ò–ú–ï–†–´ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø:
- "BL-123456 –±–æ–ª—Ç –ú12" ‚Üí contractor_article: "BL-123456", description: "–±–æ–ª—Ç –ú12"
- "–ê–ì–ë-789012" ‚Üí agb_article: "–ê–ì–ë-789012"
- "10 —à—Ç –≥–∞–π–∫–∞ –ú10" ‚Üí quantity: 10, unit: "—à—Ç", description: "–≥–∞–π–∫–∞ –ú10"
- "—Ç—Ä—É–±–∞ 100–º" ‚Üí quantity: 100, unit: "–º", description: "—Ç—Ä—É–±–∞"

–í–ï–†–ù–ò –¢–û–õ–¨–ö–û JSON –ú–ê–°–°–ò–í!"""
                    },
                    {
                        "role": "user",
                        "content": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç –∏ –Ω–∞–π–¥–∏ –∞—Ä—Ç–∏–∫—É–ª—ã:\n\n{text}"
                    }
                ]
            )
            return response.choices[0].message.content
        elif provider == 'polza':
            # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Polza.ai —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": "gpt-4o-mini",
                "messages": [
                    {
                        "role": "system",
                        "content": """–¢–´ - –ò–ò-–°–ü–ï–¶–ò–ê–õ–ò–°–¢ –ü–û –ò–ó–í–õ–ï–ß–ï–ù–ò–Æ –ò –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Æ –ê–†–¢–ò–ö–£–õ–û–í –ö–û–ú–ü–ê–ù–ò–ò –ê–ì–ë.

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –¢–í–û–Ø –û–°–ù–û–í–ù–ê–Ø –ó–ê–î–ê–ß–ê: –ò–∑–≤–ª–µ–∫–∞—Ç—å –∞—Ä—Ç–∏–∫—É–ª—ã –∏ —Ç–æ–≤–∞—Ä—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤/—Ç–µ–∫—Å—Ç–∞
2. –ï–°–õ–ò —ç—Ç–æ –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–∏—Å–∫ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–µ—Ä–Ω–∏ JSON —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
3. –ï–°–õ–ò —ç—Ç–æ –æ–±—ã—á–Ω—ã–π —á–∞—Ç - –æ—Ç–≤–µ—á–∞–π –∫–∞–∫ –ø–æ–º–æ—â–Ω–∏–∫

–ü–†–ò–ó–ù–ê–ö–ò –ê–†–¢–ò–ö–£–õ–û–í –ö–û–ú–ü–ê–ù–ò–ò –ê–ì–ë:
- –§–æ—Ä–º–∞—Ç: –ê–ì–ë-XXXXXX, –ê–ì–ëXXXXXX (6-8 —Ü–∏—Ñ—Ä)
- BL-XXXXXX, BLXXXXXX (–∞—Ä—Ç–∏–∫—É–ª—ã "–±–æ—Ä—Ç–ª–∞–Ω–≥–µ—Ä")
- –û–•–ö–£-XXXXXX, –û–•–ö–£XXXXXX (–∞—Ä—Ç–∏–∫—É–ª—ã)
- –ö–æ–¥—ã 1–°: —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–¥—ã (–£–¢-–∫–æ–¥—ã)
- –°–æ—á–µ—Ç–∞–Ω–∏—è: —Ü–∏—Ñ—Ä—ã + –±—É–∫–≤—ã (1234BL, BL1234)

–ò–ó–í–õ–ï–ö–ê–ô –ò–ù–§–û–†–ú–ê–¶–ò–Æ:
- –ê—Ä—Ç–∏–∫—É–ª—ã –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤ (–ª—é–±—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã)
- –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ (–Ω–∞ —Ä—É—Å—Å–∫–æ–º/–∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
- –û–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê –î–õ–Ø –ê–†–¢–ò–ö–£–õ–û–í:
[
    {
        "contractor_article": "–∞—Ä—Ç–∏–∫—É–ª –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)",
        "description": "–ø–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞",
        "quantity": —á–∏—Å–ª–æ,
        "unit": "—à—Ç/–∫–≥/–ª/–º¬≤/–º¬≥",
        "agb_article": "–∞—Ä—Ç–∏–∫—É–ª –ê–ì–ë (–µ—Å–ª–∏ –ø–æ—Ö–æ–∂)",
        "bl_article": "BL –∞—Ä—Ç–∏–∫—É–ª (–µ—Å–ª–∏ –ø–æ—Ö–æ–∂)",
        "match_confidence": 85,
        "match_type": "exact/partial/by_name"
    }
]

–ü–†–ê–í–ò–õ–ê –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø:
- –ò–©–ò –í–°–ï –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã –≤ —Ç–µ–∫—Å—Ç–µ
- –ù–ï –ü–†–û–ü–£–°–ö–ê–ô —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ - –æ–Ω–∏ —Ç–æ–∂–µ –≤–∞–∂–Ω—ã
- –ï–°–õ–ò –∞—Ä—Ç–∏–∫—É–ª —Å–æ–¥–µ—Ä–∂–∏—Ç "BL", "–±–æ—Ä—Ç" - —ç—Ç–æ BL –∞—Ä—Ç–∏–∫—É–ª
- –ï–°–õ–ò –∞—Ä—Ç–∏–∫—É–ª —Å–æ–¥–µ—Ä–∂–∏—Ç "–ê–ì–ë" - —ç—Ç–æ –ê–ì–ë –∞—Ä—Ç–∏–∫—É–ª
- –ö–û–õ–ò–ß–ï–°–¢–í–û: –∏—â–∏ —á–∏—Å–ª–∞ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è
- –ï–°–õ–ò –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–µ—Ç - —Å—Ç–∞–≤—å 1

–ü–†–ò–ú–ï–†–´ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø:
- "BL-123456 –±–æ–ª—Ç –ú12" ‚Üí contractor_article: "BL-123456", description: "–±–æ–ª—Ç –ú12"
- "–ê–ì–ë-789012" ‚Üí agb_article: "–ê–ì–ë-789012"
- "10 —à—Ç –≥–∞–π–∫–∞ –ú10" ‚Üí quantity: 10, unit: "—à—Ç", description: "–≥–∞–π–∫–∞ –ú10"
- "—Ç—Ä—É–±–∞ 100–º" ‚Üí quantity: 100, unit: "–º", description: "—Ç—Ä—É–±–∞"

–í–ï–†–ù–ò –¢–û–õ–¨–ö–û JSON –ú–ê–°–°–ò–í!"""
                    },
                    {
                        "role": "user",
                        "content": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç –∏ –Ω–∞–π–¥–∏ –∞—Ä—Ç–∏–∫—É–ª—ã:\n\n{text}"
                    }
                ],
                "temperature": 0.1,
                "max_tokens": 2000
            }
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º URL –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Polza.ai
            POLZA_API_URL = "https://api.polza.ai/v1/chat/completions"
            
            print(f"DEBUG: Sending request to Polza.ai with key: {api_key[:10]}...")
            print(f"DEBUG: Request data: {data}")
            
            async with aiohttp.ClientSession() as session:
                async with session.post(POLZA_API_URL, headers=headers, json=data) as response:
                    print(f"DEBUG: Polza.ai response status: {response.status}")
                    if response.status in [200, 201]:
                        result = await response.json()
                        print(f"DEBUG: Polza.ai response: {result}")
                        return result["choices"][0]["message"]["content"]
                    else:
                        error_text = await response.text()
                        print(f"DEBUG: Polza.ai error: {error_text}")
                        raise Exception(f"–û—à–∏–±–∫–∞ Polza.ai API {response.status}: {error_text}")
        else:
            raise Exception(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {provider}")
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò: {str(e)}")

async def match_articles_with_database(articles: List[dict], db: AsyncSession) -> List[MatchingResult]:
    """–°–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
    print(f"üîç match_articles_with_database –≤—ã–∑–≤–∞–Ω–∞ —Å {len(articles)} –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏")
    results = []
    
    for article in articles:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ article - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
        if not isinstance(article, dict):
            print(f"‚ùå –û—à–∏–±–∫–∞: article –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º, –ø–æ–ª—É—á–µ–Ω: {type(article)}")
            return []

        contractor_article = article.get('contractor_article')
        description = article.get('description')

        # –ï—Å–ª–∏ –Ω–µ—Ç –∞—Ä—Ç–∏–∫—É–ª–∞ –∏ –æ–ø–∏—Å–∞–Ω–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if not contractor_article and not description:
            print(f"‚ùå –û—à–∏–±–∫–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç contractor_article –∏ description")
            results.append(MatchingResult(
                id=str(uuid.uuid4()),
                contractor_article='',
                description='–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä',
                matched=False,
                match_confidence=0.0
            ))
            return results

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ AI
        search_text = f"{contractor_article or ''} {description or ''}".strip()
        print(f"üîç –í—ã–∑—ã–≤–∞–µ–º smart_search_with_ai –¥–ª—è: '{search_text}'")
        print(f"üîç contractor_article: '{contractor_article}'")
        print(f"üîç description: '{description}'")
        
        try:
            ai_search_result = await smart_search_with_ai(search_text, db)
            print(f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç smart_search_with_ai: {ai_search_result}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ smart_search_with_ai: {e}")
            import traceback
            traceback.print_exc()
            ai_search_result = None
        
        if ai_search_result and ai_search_result.get('matches'):
            best_match = ai_search_result['matches'][0]  # –ë–µ—Ä–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: {best_match}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–∏—Å–∫–∞ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è
            search_type = ai_search_result.get('search_type', 'ai_search')
            is_existing = best_match.get('is_existing', False)
            
            results.append(MatchingResult(
                id=str(uuid.uuid4()),
                contractor_article=contractor_article,
                description=description,
                matched=True,
                agb_article=best_match.get('agb_article'),
                bl_article=best_match.get('bl_article'),
                match_confidence=best_match.get('confidence', 0.0),
                nomenclature={
                    'id': 0,
                    'name': best_match.get('name', ''),
                    'code_1c': best_match.get('code_1c', ''),
                    'article': best_match.get('agb_article', '')
                },
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ –ø–æ–∏—Å–∫–∞
                search_type=search_type,
                is_existing_mapping=is_existing,
                mapping_id=best_match.get('mapping_id') if is_existing else None
            ))
        else:
            # –ï—Å–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
            results.append(MatchingResult(
                id=str(uuid.uuid4()),
                contractor_article=contractor_article,
                description=description,
                matched=False,
                match_confidence=0.0
            ))
    
    return results

async def find_exact_article_match(contractor_article: str, db: AsyncSession) -> Optional[dict]:
    """–ù–∞–π—Ç–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∞—Ä—Ç–∏–∫—É–ª–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        from sqlalchemy.future import select

        # –ï—Å–ª–∏ contractor_article None –∏–ª–∏ –ø—É—Å—Ç–æ–π, –Ω–µ –∏—â–µ–º
        if not contractor_article:
            return None

        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É
        result = await db.execute(
            select(MatchingNomenclature).where(
                MatchingNomenclature.agb_article == contractor_article
            ).limit(1)
        )
        match = result.scalar_one_or_none()

        if match:
            return {
                'id': match.id,
                'name': match.name,
                'code_1c': match.code_1c,
                'agb_article': match.agb_article,
                'bl_article': match.bl_article,
                'confidence': 100.0
            }

        return None
    except Exception as e:
        print(f"Error in find_exact_article_match: {e}")
        return None

async def find_partial_article_match(contractor_article: str, description: str, db: AsyncSession) -> Optional[dict]:
    """–ù–∞–π—Ç–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∞—Ä—Ç–∏–∫—É–ª–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        from sqlalchemy.future import select
        import difflib
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã
        result = await db.execute(select(MatchingNomenclature))
        nomenclatures = result.scalars().all()
        
        best_match = None
        best_confidence = 0
        
        for nom in nomenclatures:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É
            article_confidence = 0
            if contractor_article and nom.agb_article:
                article_confidence = SequenceMatcher(
                    None, contractor_article.lower(), nom.agb_article.lower()
                ).ratio() * 100
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—é
            name_confidence = 0
            if description and nom.name:
                name_confidence = SequenceMatcher(
                    None, description.lower(), nom.name.lower()
                ).ratio() * 100
            
            # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence = max(article_confidence, name_confidence)
            
            if confidence > best_confidence and confidence >= 80:
                best_confidence = confidence
                best_match = {
                    'id': nom.id,
                    'name': nom.name,
                    'code_1c': nom.code_1c,
                    'agb_article': nom.agb_article,
                    'bl_article': nom.bl_article,
                    'confidence': confidence
                }
        
        return best_match
    except Exception as e:
        print(f"Error in find_partial_article_match: {e}")
        return None

@router.post("/ai-process/", response_model=AIMatchingResponse)
async def process_ai_request(
    message: str = Form(...),
    files: List[UploadFile] = File(default=[]),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –ò–ò-–∞–≥–µ–Ω—Ç—É"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º Polza.ai
        result = await db.execute(select(ApiKey).where(
            ApiKey.is_active == True,
            ApiKey.provider == 'polza'
        ).limit(1))
        api_key_obj = result.scalar_one_or_none()
        
        # –ï—Å–ª–∏ Polza.ai –∫–ª—é—á–∞ –Ω–µ—Ç, –±–µ—Ä–µ–º OpenAI
        if not api_key_obj:
            result = await db.execute(select(ApiKey).where(
                ApiKey.is_active == True,
                ApiKey.provider == 'openai'
            ).limit(1))
            api_key_obj = result.scalar_one_or_none()
        
        if not api_key_obj:
            return AIMatchingResponse(
                message="–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ API –∫–ª—é—á–∞ –¥–ª—è –ò–ò-—Å–µ—Ä–≤–∏—Å–∞. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.",
                matching_results=[],
                processing_time=0.1,
                status="error"
            )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
        extracted_text = message
        file_paths = []
        
        for file in files:
            if not is_allowed_file(file.filename):
                return AIMatchingResponse(
                    message=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {file.filename}",
                    matching_results=[],
                    processing_time=0.1,
                    status="error"
                )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            file_id = str(uuid.uuid4())
            file_path = UPLOAD_DIR / f"{file_id}_{file.filename}"
            
            with open(file_path, "wb") as buffer:
                content = await file.read()
                buffer.write(content)
            
            file_paths.append(str(file_path))
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
            try:
                file_text = await extract_text_from_file(str(file_path), file.filename)
                extracted_text += f"\n\n--- –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ {file.filename} ---\n{file_text}"
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file.filename}: {str(e)}")
                continue
        
        # –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ–º –∫–ª—é—á
        try:
            from cryptography.fernet import Fernet
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª—é—á, —á—Ç–æ –∏ –≤ settings.py
            ENCRYPTION_KEY = b'iF0d2ARGQpaU9GFfQdWNovBL239dqwTp9hDDPrDQQic='
            cipher_suite = Fernet(ENCRYPTION_KEY)
            decrypted_key = cipher_suite.decrypt(api_key_obj.key.encode()).decode()
            print(f"DEBUG: Successfully decrypted key for {api_key_obj.provider}")
        except Exception as e:
            print(f"DEBUG: Decryption failed: {str(e)}")
            print(f"DEBUG: Key length: {len(api_key_obj.key)}")
            print(f"DEBUG: Key starts with: {api_key_obj.key[:20]}...")
            # –í–æ–∑–º–æ–∂–Ω–æ, –∫–ª—é—á –Ω–µ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
            decrypted_key = api_key_obj.key
            print(f"DEBUG: Using key directly: {decrypted_key[:10]}...")
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –∏–∑ –∫–ª—é—á–∞
        decrypted_key = decrypted_key.strip()
        print(f"DEBUG: Final key for {api_key_obj.provider}: {decrypted_key[:20]}...")
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò
        try:
            print(f"üîç –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ AI: '{extracted_text}'")
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò
            ai_response = await get_ai_response(extracted_text, decrypted_key, api_key_obj.provider)
            print(f"üîç AI –æ—Ç–≤–µ—Ç: {ai_response}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ—Ç–≤–µ—Ç JSON —Å –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏
            articles = []
            matching_results = []
            
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            try:
                # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                clean_response = ai_response
                if '```json' in clean_response:
                    clean_response = clean_response.split('```json')[1].split('```')[0].strip()
                elif '```' in clean_response:
                    clean_response = clean_response.split('```')[1].split('```')[0].strip()
                
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ
                if clean_response.strip().startswith('[') and clean_response.strip().endswith(']'):
                    articles = json.loads(clean_response)
                    print(f"DEBUG: Found articles in response: {len(articles)}")
                    print(f"DEBUG: Articles content: {articles}")
                else:
                    # –ò—â–µ–º JSON –≤ —Ç–µ–∫—Å—Ç–µ
                    import re
                    json_match = re.search(r'\[.*?\]', clean_response, re.DOTALL)
                    if json_match:
                        articles = json.loads(json_match.group())
                        print(f"DEBUG: Found articles in text: {len(articles)}")
                    else:
                        print(f"DEBUG: No JSON found, treating as regular chat response")
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
                        if clean_response and len(clean_response.strip()) > 10:
                            print(f"üîç –ü–æ–ø—ã—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: {clean_response[:100]}...")
                            articles = [{
                                'contractor_article': '',
                                'description': clean_response.strip(),
                                'quantity': 1,
                                'unit': '—à—Ç'
                            }]
                            print(f"üîç –°–æ–∑–¥–∞–Ω –∞—Ä—Ç–∏–∫—É–ª –∏–∑ –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {articles[0]}")
                        else:
                            print(f"DEBUG: Treating as regular chat response")
                            pass
            except json.JSONDecodeError as e:
                print(f"DEBUG: JSON parsing error: {e}")
                print(f"DEBUG: Response: {ai_response}")
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, –ø—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
                if ai_response and len(ai_response.strip()) > 10:
                    print(f"üîç –ü–æ–ø—ã—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: {ai_response[:100]}...")
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
                    articles = [{
                        'contractor_article': '',
                        'description': ai_response.strip(),
                        'quantity': 1,
                        'unit': '—à—Ç'
                    }]
                    print(f"üîç –°–æ–∑–¥–∞–Ω –∞—Ä—Ç–∏–∫—É–ª –∏–∑ –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {articles[0]}")
                else:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, —ç—Ç–æ –æ–±—ã—á–Ω—ã–π —á–∞—Ç
                    pass
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –∞—Ä—Ç–∏–∫—É–ª—ã, —Å–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            if articles:
                print(f"üîç HTTP API: –ù–∞–π–¥–µ–Ω–æ {len(articles)} –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –≤ AI –æ—Ç–≤–µ—Ç–µ")
                for article in articles:
                    print(f"üîç HTTP API: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª: {article}")
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ò–ò –æ—Ç–≤–µ—Ç–∞
                    normalized_article = normalize_ai_article(article)

                    # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
                    print(f"üîç HTTP API: –í—ã–∑—ã–≤–∞–µ–º match_articles_with_database...")
                    matched_result = await match_articles_with_database([normalized_article], db)
                    print(f"üîç HTTP API: –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: {matched_result}")
                    if matched_result:
                        print(f"üîç HTTP API: –î–æ–±–∞–≤–ª—è–µ–º {len(matched_result)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        matching_results.extend(matched_result)
                    else:
                        print(f"üîç HTTP API: –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è {normalized_article.get('contractor_article', normalized_article.get('description', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä'))}")
                        # –ï—Å–ª–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        matching_results.append(MatchingResult(
                            id=str(uuid.uuid4()),
                            contractor_article=normalized_article.get('contractor_article'),
                            description=normalized_article.get('description'),
                            matched=False,
                            agb_article=normalized_article.get('agb_article'),
                            bl_article=normalized_article.get('bl_article'),
                            match_confidence=normalized_article.get('match_confidence'),
                            nomenclature=normalized_article.get('nomenclature')
                        ))
            else:
                print(f"üîç HTTP API: –ù–µ—Ç –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            for file_path in file_paths:
                try:
                    Path(file_path).unlink()
                except:
                    pass
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
            if articles or matching_results:
                message = f"–ù–∞–π–¥–µ–Ω–æ {len(matching_results)} –∞—Ä—Ç–∏–∫—É–ª–æ–≤:\n\n"
                for i, result in enumerate(matching_results, 1):
                    if result.matched:
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–∏—Å–∫–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                        search_info = ""
                        if hasattr(result, 'is_existing_mapping') and result.is_existing_mapping:
                            search_info = " (—É–∂–µ –±—ã–ª —Ç–∞–∫–æ–π –∑–∞–ø—Ä–æ—Å) üîÑ"
                        elif hasattr(result, 'search_type') and result.search_type == 'existing_mapping_by_description':
                            search_info = " (–Ω–∞–π–¥–µ–Ω–æ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é) üîç"
                        elif hasattr(result, 'search_type') and result.search_type == 'ai_search':
                            search_info = " (–ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –ò–ò) ü§ñ"
                        
                        message += f"{i}. ‚úÖ {result.contractor_article} - {result.description}{search_info}\n"
                        message += f"   ‚Üí –ê–ì–ë: {result.agb_article} | BL: {result.bl_article} | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.match_confidence:.1f}%\n\n"
                    else:
                        message += f"{i}. ‚ùå {result.contractor_article} - {result.description} (–Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –ë–î)\n\n"
            else:
                # –û–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç —á–∞—Ç–∞
                message = ai_response
            
            return AIMatchingResponse(
                message=message,
                matching_results=matching_results,
                processing_time=0.5,
                status="completed"
            )
            
        except Exception as e:
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            for file_path in file_paths:
                try:
                    Path(file_path).unlink()
                except:
                    pass
            
            return AIMatchingResponse(
                message=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ò–ò: {str(e)}",
                matching_results=[],
                processing_time=0.1,
                status="error"
            )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")

# –ù–æ–≤—ã–µ endpoints –¥–ª—è Excel —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞

@router.post("/parse-excel/", response_model=ExcelParseResponse)
async def parse_excel_file(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db)
):
    """
    –ü–∞—Ä—Å–∏—Ç Excel —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
        if not file.filename.endswith(('.xlsx', '.xls')):
            raise HTTPException(status_code=400, detail="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã .xlsx –∏ .xls")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        contents = await file.read()
        
        # –ü–∞—Ä—Å–∏–º Excel
        try:
            df = pd.read_excel(io.BytesIO(contents))
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Excel —Ñ–∞–π–ª–∞: {str(e)}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        excel_rows = []
        for index, row in df.iterrows():
            excel_row = ExcelRow(
                id=f"row_{index + 1}",
                –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ=str(row.get('–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '')),
                –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π_–∞—Ä—Ç–∏–∫—É–ª=str(row.get('–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π –∞—Ä—Ç–∏–∫—É–ª', '')),
                –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ=float(row.get('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', 1)),
                –µ–¥–∏–Ω–∏—Ü–∞_–∏–∑–º–µ—Ä–µ–Ω–∏—è=str(row.get('–ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è', '—à—Ç')),
                –Ω–∞—à_–∞—Ä—Ç–∏–∫—É–ª=str(row.get('–ù–∞—à –∞—Ä—Ç–∏–∫—É–ª', '')) if pd.notna(row.get('–ù–∞—à –∞—Ä—Ç–∏–∫—É–ª')) else None,
                –∞—Ä—Ç–∏–∫—É–ª_bl=str(row.get('–ê—Ä—Ç–∏–∫—É–ª BL', '')) if pd.notna(row.get('–ê—Ä—Ç–∏–∫—É–ª BL')) else None,
                –Ω–æ–º–µ—Ä_1—Å=str(row.get('–ù–æ–º–µ—Ä –≤ 1–°', '')) if pd.notna(row.get('–ù–æ–º–µ—Ä –≤ 1–°')) else None,
                —Å—Ç–æ–∏–º–æ—Å—Ç—å=float(row.get('–°—Ç–æ–∏–º–æ—Å—Ç—å', 0)) if pd.notna(row.get('–°—Ç–æ–∏–º–æ—Å—Ç—å')) else None,
                —Å—Ç–∞—Ç—É—Å_—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è="pending",
                —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å=0
            )
            excel_rows.append(excel_row)
        
        return ExcelParseResponse(
            success=True,
            data=excel_rows,
            message=f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(excel_rows)} —Å—Ç—Ä–æ–∫"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")

@router.post("/auto-match-excel/", response_model=ExcelMatchResponse)
async def auto_match_excel_data(
    request: ExcelDataRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ Excel –¥–∞–Ω–Ω—ã—Ö —Å –±–∞–∑–æ–π
    """
    try:
        matched_data = []
        statistics = {
            "total": len(request.data),
            "matched": 0,
            "unmatched": 0,
            "pending": 0
        }
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—é
        async for db in get_db():
            name_query = select(MatchingNomenclature).where(
                MatchingNomenclature.is_active == True
            )
            name_results = await db.execute(name_query)
            name_items = name_results.scalars().all()
            
            print(f"DEBUG: –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(name_items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–∑ –±–∞–∑—ã")
            print(f"DEBUG: –ü–æ–ª—É—á–µ–Ω–æ {len(request.data)} —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            
            for row in request.data:
                matched_row = row.copy()
                print(f"DEBUG: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É: '{row.–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ}'")
                
                # –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—é (70% —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
                if row.–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ:
                    print(f"DEBUG: –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—é: '{row.–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ}'")
                    search_text = row.–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ.lower().strip()
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –í–°–ï –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å –∏—Ö —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ö–æ–∂–µ—Å—Ç—å—é
                    matches = []
                    
                    # 1. –ü–æ–∏—Å–∫ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ (–±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π)
                    for item in name_items:
                        item_name = item.name.lower()
                        if search_text in item_name:
                            # –î–ª—è –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —Å—Ö–æ–∂–µ—Å—Ç—å
                            # –í—ã—á–∏—Å–ª—è–µ–º –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ –∫ –¥–ª–∏–Ω–µ –ø–æ–ª–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è
                            substring_ratio = len(search_text) / len(item_name)
                            # –ú–∏–Ω–∏–º—É–º 0.5, –º–∞–∫—Å–∏–º—É–º 1.0
                            similarity = max(0.5, min(1.0, substring_ratio + 0.3))
                            
                            matches.append({
                                'item': item,
                                'similarity': similarity,
                                'confidence': int(similarity * 100),
                                'match_type': 'substring'
                            })
                            print(f"DEBUG: –ù–∞–π–¥–µ–Ω–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–æ–≤–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: '{item.name}' (—Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.2f})")
                    
                    # 2. –ü–æ–∏—Å–∫ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É –¥–ª—è –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                    for item in name_items:
                        item_name = item.name.lower()
                        normalized_search = get_normalized_text(search_text)
                        normalized_item = get_normalized_text(item_name)
                        similarity = SequenceMatcher(None, normalized_search, normalized_item).ratio()
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å—Ö–æ–∂–µ—Å—Ç—å >= 50% –∏ —ç—Ç–æ –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç
                        if similarity >= 0.5:  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª—å—à–µ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç
                            is_duplicate = any(
                                match['item'].id == item.id for match in matches
                            )
                            if not is_duplicate:
                                matches.append({
                                    'item': item,
                                    'similarity': similarity,
                                    'confidence': int(similarity * 100),
                                    'match_type': 'normalized'
                                })
                                print(f"DEBUG: –ù–∞–π–¥–µ–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: '{item.name}' (—Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.2f})")
                    
                    # 3. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                    search_words = search_text.split()
                    if len(search_words) > 1:  # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤
                        for item in name_items:
                            item_name = item.name.lower()
                            word_matches = 0
                            total_words = len(search_words)
                            
                            for word in search_words:
                                if word in item_name:
                                    word_matches += 1
                            
                            if word_matches > 0:
                                word_similarity = word_matches / total_words
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç
                                is_duplicate = any(
                                    match['item'].id == item.id for match in matches
                                )
                                if not is_duplicate and word_similarity >= 0.3:
                                    matches.append({
                                        'item': item,
                                        'similarity': word_similarity,
                                        'confidence': int(word_similarity * 100),
                                        'match_type': 'keywords'
                                    })
                                    print(f"DEBUG: –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: '{item.name}' (—Å—Ö–æ–∂–µ—Å—Ç—å: {word_similarity:.2f})")
                    
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–∂–µ—Å—Ç–∏
                    matches.sort(key=lambda x: x['similarity'], reverse=True)
                    
                    if matches:
                        # –ë–µ—Ä–µ–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–ª–µ–π (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å—Ö–æ–∂–µ—Å—Ç—å >= 70%)
                        best_match = matches[0]
                        if best_match['similarity'] >= 0.7:
                            matched_row.–Ω–∞—à_–∞—Ä—Ç–∏–∫—É–ª = best_match['item'].agb_article
                            matched_row.–∞—Ä—Ç–∏–∫—É–ª_bl = best_match['item'].bl_article
                            matched_row.–Ω–æ–º–µ—Ä_1—Å = best_match['item'].code_1c
                            matched_row.—Å—Ç–∞—Ç—É—Å_—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è = "matched"
                            matched_row.—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å = best_match['confidence']
                        else:
                            matched_row.—Å—Ç–∞—Ç—É—Å_—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è = "partial"
                            matched_row.—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å = best_match['confidence']
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –í–°–ï –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤ –ø–æ–ª–µ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (—Ç–æ–ø 10)
                        matched_row.–≤–∞—Ä–∏–∞–Ω—Ç—ã_–ø–æ–¥–±–æ—Ä–∞ = [
                            {
                                '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': match['item'].name,
                                '–Ω–∞—à_–∞—Ä—Ç–∏–∫—É–ª': match['item'].agb_article,
                                '–∞—Ä—Ç–∏–∫—É–ª_bl': match['item'].bl_article,
                                '–Ω–æ–º–µ—Ä_1—Å': match['item'].code_1c,
                                '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': match['confidence'],
                                '—Ç–∏–ø_—Å–æ–≤–ø–∞–¥–µ–Ω–∏—è': match['match_type']
                            }
                            for match in matches[:10]  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 10 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
                        ]
                        
                        matched_data.append(matched_row)
                        if best_match['similarity'] >= 0.7:
                            statistics["matched"] += 1
                        else:
                            statistics["pending"] += 1
                        print(f"DEBUG: –î–æ–±–∞–≤–ª–µ–Ω–æ {len(matches)} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –¥–ª—è '{row.–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ}'")
                    else:
                        matched_row.—Å—Ç–∞—Ç—É—Å_—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è = "unmatched"
                        matched_row.–≤–∞—Ä–∏–∞–Ω—Ç—ã_–ø–æ–¥–±–æ—Ä–∞ = []
                        matched_data.append(matched_row)
                        statistics["unmatched"] += 1
                        print(f"DEBUG: –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –¥–ª—è '{row.–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ}'")
                    continue
                
                # –ü–æ–∏—Å–∫ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É (100% —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
                elif row.–∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π_–∞—Ä—Ç–∏–∫—É–ª:
                    print(f"DEBUG: –ü–æ–∏—Å–∫ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É: '{row.–∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π_–∞—Ä—Ç–∏–∫—É–ª}'")
                    # –ü–æ–∏—Å–∫ –≤ –Ω–∞—à–µ–π –±–∞–∑–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É –ê–ì–ë
                    agb_query = select(MatchingNomenclature).where(
                        MatchingNomenclature.agb_article == row.–∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π_–∞—Ä—Ç–∏–∫—É–ª
                    )
                    agb_result = await db.execute(agb_query)
                    agb_item = agb_result.scalar_one_or_none()
                    
                    # –ü–æ–∏—Å–∫ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É BL
                    bl_query = select(MatchingNomenclature).where(
                        MatchingNomenclature.bl_article == row.–∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π_–∞—Ä—Ç–∏–∫—É–ª
                    )
                    bl_result = await db.execute(bl_query)
                    bl_item = bl_result.scalar_one_or_none()
                    
                    if agb_item:
                        matched_row.–Ω–∞—à_–∞—Ä—Ç–∏–∫—É–ª = agb_item.agb_article
                        matched_row.–∞—Ä—Ç–∏–∫—É–ª_bl = agb_item.bl_article
                        matched_row.–Ω–æ–º–µ—Ä_1—Å = agb_item.code_1c
                        matched_row.—Å—Ç–∞—Ç—É—Å_—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è = "matched"
                        matched_row.—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å = 100
                        matched_row.–≤–∞—Ä–∏–∞–Ω—Ç—ã_–ø–æ–¥–±–æ—Ä–∞ = [{
                            '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': agb_item.name,
                            '–Ω–∞—à_–∞—Ä—Ç–∏–∫—É–ª': agb_item.agb_article,
                            '–∞—Ä—Ç–∏–∫—É–ª_bl': agb_item.bl_article,
                            '–Ω–æ–º–µ—Ä_1—Å': agb_item.code_1c,
                            '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': 100
                        }]
                        matched_data.append(matched_row)
                        statistics["matched"] += 1
                    elif bl_item:
                        matched_row.–Ω–∞—à_–∞—Ä—Ç–∏–∫—É–ª = bl_item.agb_article
                        matched_row.–∞—Ä—Ç–∏–∫—É–ª_bl = bl_item.bl_article
                        matched_row.–Ω–æ–º–µ—Ä_1—Å = bl_item.code_1c
                        matched_row.—Å—Ç–∞—Ç—É—Å_—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è = "matched"
                        matched_row.—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å = 100
                        matched_row.–≤–∞—Ä–∏–∞–Ω—Ç—ã_–ø–æ–¥–±–æ—Ä–∞ = [{
                            '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': bl_item.name,
                            '–Ω–∞—à_–∞—Ä—Ç–∏–∫—É–ª': bl_item.agb_article,
                            '–∞—Ä—Ç–∏–∫—É–ª_bl': bl_item.bl_article,
                            '–Ω–æ–º–µ—Ä_1—Å': bl_item.code_1c,
                            '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': 100
                        }]
                        matched_data.append(matched_row)
                        statistics["matched"] += 1
                    else:
                        matched_row.—Å—Ç–∞—Ç—É—Å_—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è = "unmatched"
                        matched_row.–≤–∞—Ä–∏–∞–Ω—Ç—ã_–ø–æ–¥–±–æ—Ä–∞ = []
                        matched_data.append(matched_row)
                        statistics["unmatched"] += 1
                else:
                    matched_row.—Å—Ç–∞—Ç—É—Å_—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è = "unmatched"
                    matched_row.–≤–∞—Ä–∏–∞–Ω—Ç—ã_–ø–æ–¥–±–æ—Ä–∞ = []
                    matched_data.append(matched_row)
                    statistics["unmatched"] += 1
        
        return ExcelMatchResponse(
            success=True,
            matched_data=matched_data,
            statistics=statistics,
            message=f"–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ù–∞–π–¥–µ–Ω–æ {statistics['matched']} –∏–∑ {statistics['total']} –ø–æ–∑–∏—Ü–∏–π"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: {str(e)}")

@router.post("/save-excel-results/")
async def save_excel_results(
    request: ExcelDataRequest,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Excel —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        saved_count = 0
        
        for row in request.data:
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ —Ç–∞–±–ª–∏—Ü–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π
            mapping_data = {
                "contractor_article": row.–∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π_–∞—Ä—Ç–∏–∫—É–ª,
                "contractor_description": row.–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ,
                "agb_article": row.–Ω–∞—à_–∞—Ä—Ç–∏–∫—É–ª or "",
                "agb_description": "",  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã
                "bl_article": row.–∞—Ä—Ç–∏–∫—É–ª_bl or "",
                "bl_description": "",  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ BL
                "packaging_factor": 1.0,
                "unit": row.–µ–¥–∏–Ω–∏—Ü–∞_–∏–∑–º–µ—Ä–µ–Ω–∏—è,
                "quantity": row.–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ,
                "cost": row.—Å—Ç–æ–∏–º–æ—Å—Ç—å or 0.0,
                "match_confidence": row.—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å or 0,
                "status": row.—Å—Ç–∞—Ç—É—Å_—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è or "pending",
                "created_by": current_user.id,
                "created_at": datetime.utcnow()
            }
            
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            # –ù–∞–ø—Ä–∏–º–µ—Ä, —Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ ArticleMapping
            saved_count += 1
        
        return {
            "success": True,
            "message": f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –∑–∞–ø–∏—Å–µ–π",
            "saved_count": saved_count
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")

@router.get("/saved-variants/")
async def get_saved_variants(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø–æ–¥–±–æ—Ä–∞"""
    try:
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        return {
            "success": True,
            "saved_variants": {}
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏: {str(e)}")

@router.post("/save-variant-selection/")
async def save_variant_selection(
    request: dict,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –ø–æ–¥–±–æ—Ä–∞"""
    try:
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        # request –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å: {"row_id": "string", "variant_index": int}
        
        return {
            "success": True,
            "message": "–í–∞—Ä–∏–∞–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω"
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {str(e)}")
